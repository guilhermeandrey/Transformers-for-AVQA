{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data setup"
      ],
      "metadata": {
        "id": "4iA5XKt1A4nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "Import modules"
      ],
      "metadata": {
        "id": "24fasZYuFAkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlXXuKRX2xUk",
        "outputId": "4321da72-6b12-4c4d-b122-bef7817b3f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.9.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wO0Ca8KFVU7"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torchmetrics as tm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from scipy.io import loadmat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import pickle\n",
        "from time import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "import math\n",
        "from copy import copy, deepcopy\n",
        "from typing import Tuple\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import dataset\n",
        "from torch.nn import TransformerEncoderLayer, TransformerEncoder\n",
        "from torch.nn import Linear, Dropout, LayerNorm\n",
        "from torchvision.models.resnet import Bottleneck"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data"
      ],
      "metadata": {
        "id": "O8V7fIT7j2g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Google Drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NDFp83DAhOFu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "266410e5-062e-43ab-ee56-c363ec0d7fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read features and labels vectors\n",
        "filename = '/content/drive/MyDrive/TCC Dados/dados.zip'\n",
        "extract_dir = '/content/'\n",
        "svpth = '/content/'\n",
        "featPath = os.path.join(svpth, 'features.npy')\n",
        "lblPath = os.path.join(svpth, 'labels.npy')\n",
        "if (not os.path.exists(featPath)) and (not os.path.exists(lblPath)):\n",
        "  shutil.unpack_archive(filename, extract_dir)\n",
        "X = np.load(featPath) # features\n",
        "y = np.load(lblPath) # labels"
      ],
      "metadata": {
        "id": "db51gqfb8UMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze data correlation\n",
        "Plot autocorrelation function to verify redundancy in data"
      ],
      "metadata": {
        "id": "fmYY4G_I5sXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "fig, ax = plt.subplots(10, 1, figsize = (14, 60))\n",
        "idxs = np.random.randint(800, size = 10)\n",
        "lags = 100 # Number of samples to calculate autocorrelation\n",
        "for i, idx in enumerate(idxs):\n",
        "  Xsample = MinMaxScaler().fit_transform(X[idx])\n",
        "  plot_acf(np.mean(Xsample, axis = 1), lags = lags, ax = ax[i])\n",
        "  ax[i].set_xticks(np.arange(0, lags + 1, 5))\n",
        "  ax[i].set_xticklabels(ax[i].get_xticks(), rotation = 90)\n",
        "  ax[i].grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wc0iEfKG5uoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data processing and auxiliar functions"
      ],
      "metadata": {
        "id": "yRL35YxTYRNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class DatasetAVQ(Dataset):\n",
        "  '''\n",
        "  Create dataset for AVQA\n",
        "  '''\n",
        "  def __init__(self, features, labels):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    features: np.ndarray\n",
        "      array of features\n",
        "    labels: np.ndarray\n",
        "      array of labels\n",
        "    '''\n",
        "      self.features = features\n",
        "      self.labels = labels\n",
        "      assert len(self.features) == len(self.labels), 'Features and labels should have equal length'\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.features)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      feature = self.features[idx]\n",
        "      label = self.labels[idx]\n",
        "      return feature, label"
      ],
      "metadata": {
        "id": "c3E1P2nKQO86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def applyTransform(X, y, transform):\n",
        "    '''\n",
        "    Apply transformation to data (e.g. MinMaxScaler)\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    X: np.ndarray\n",
        "      Array of features\n",
        "    y: np.ndarray\n",
        "      Array of labels\n",
        "    transform: sklearn.preprocessin function (MinMaxScaler, StandardScaler, etc)\n",
        "      Function to transform data\n",
        "\n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "    Xout, yout: torch.Tensor\n",
        "      Tensors with data transformed\n",
        "    '''\n",
        "    X_flat = np.reshape(X, (-1, X.shape[-1]))\n",
        "    t = transform()\n",
        "    X_flat = t.fit_transform(X_flat)\n",
        "    Xout = np.reshape(X_flat, X.shape)\n",
        "    Xout, yout = [torch.Tensor(i) for i in [Xout, y]]\n",
        "    return Xout, yout"
      ],
      "metadata": {
        "id": "ihkiiZa7a5NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AVQTransformerData():\n",
        "  '''\n",
        "  Data handler\n",
        "  '''\n",
        "  def __init__(self, matPath, mosPath, featuresName = 'avFeatures', val_size = 0.1, test_size = 0.1, \n",
        "               transform = None, shuffle = True, debug = True):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    matPath: str\n",
        "      Path to .mat files\n",
        "    mosPath: str\n",
        "      Path to labels (MOS) file\n",
        "    featuresName: str, optional\n",
        "      Name of features array in .mat file. Default: 'avFeatures'.\n",
        "    val_size: float or int, optional\n",
        "      Size of validation split. If float, value represents percentage of entire dataset to split. Default: 0.1\n",
        "    test_size: float or int, optional\n",
        "      Size of test split. If float, value represents percentage of entire dataset to split. Default: 0.1\n",
        "    transform: sklearn.preprocessing function (MinMaxScaler, StandardScaler, etc), optional\n",
        "      Function to transform data. If None (default), apply no transformation to data\n",
        "    shuffle: bool, optional\n",
        "      If True (default), shuffle data before splitting.\n",
        "    debug: bool, optional\n",
        "      If True (default), show data processing progress\n",
        "    '''\n",
        "    self.matPath = matPath\n",
        "    self.mosPath = mosPath\n",
        "    self.featuresName = featuresName\n",
        "    self.val_size = val_size\n",
        "    self.test_size = test_size\n",
        "    self.transform = transform\n",
        "    self.shuffle = shuffle\n",
        "    self.debug = debug\n",
        "\n",
        "  def readFeaturesLabels(self):\n",
        "    '''\n",
        "    Read features and labels data from .mat files\n",
        "\n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "      X: np.ndarray\n",
        "        Features array of shape (n_videos, n_frames, n_features)\n",
        "      y: np.ndarray\n",
        "        Labels array of shape (n_videos,)\n",
        "    '''\n",
        "    print('Reading data from files...')\n",
        "    # Read MOS data\n",
        "    df = pd.read_csv(self.mosPath, sep = ';')\n",
        "    df = df[['testFile', 'Mqs']].rename(columns = {'Mqs': 'MOS'})\n",
        "    # Generate labels array\n",
        "    y = df['MOS'].values.reshape(-1, 1)\n",
        "    # Treat NaN values\n",
        "    dfHRC = df[df['testFile'].str.contains('HRC')]\n",
        "    meanHRC = np.nanmean(dfHRC['MOS'].values)\n",
        "    inds = np.where(np.isnan(y))\n",
        "    y[inds] = np.take(meanHRC, inds[1])\n",
        "    y = y.flatten()\n",
        "    # Read features data\n",
        "    files = df['testFile'].apply(lambda x: os.path.join(self.matPath, x + '.mat')).values\n",
        "    # Transpose array and clip to minimum length\n",
        "    arrays = [np.transpose(loadmat(i)[self.featuresName]) for i in files]\n",
        "    minLen = min(arrays, key = len).shape[0]\n",
        "    arrays = [t[:minLen] for t in arrays]\n",
        "    X = np.stack(arrays, axis = 0)\n",
        "    if self.debug:\n",
        "      print(f'X shape: {X.shape}\\ny shape: {y.shape}\\n')\n",
        "    self.X, self.y = X, y\n",
        "    return X, y\n",
        "\n",
        "  def dataPreparation(self, read_data = False, X = None, y = None, train_val_test_data = None):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    read_data: bool, optional\n",
        "      If True, read data from .mat files. Else, read from X and y parameters. Ignored if train_val_test_data is not None. Default: False\n",
        "    X: bool, optional\n",
        "      Features array. Ignored if read_data or train_val_test_data are True. Default: None\n",
        "    y: bool, optional\n",
        "      Labels array. Ignored if read_data or train_val_test_data are True. Default: None\n",
        "    train_val_test_data: list, optional\n",
        "      List with arrays train, test and validation arrays, with format [X_train, X_val, X_test, y_train, y_val, y_test], if\n",
        "      using test data, else [X_train, X_val, y_train, y_val]\n",
        "\n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "    X_train: torch.Tensor\n",
        "      Training features array\n",
        "    X_val: torch.Tensor\n",
        "      Validation features array\n",
        "    X_test: torch.Tensor\n",
        "      Test features array, only if using test data\n",
        "    y_train: torch.Tensor\n",
        "      Training labels array\n",
        "    y_val: torch.Tensor\n",
        "      Validation labels array\n",
        "    y_test: torch.Tensor\n",
        "      Test labels array, only if using test data\n",
        "    '''\n",
        "    # Read data from .mat files\n",
        "    if read_data:\n",
        "      X, y = self.readFeaturesLabels()\n",
        "    else:\n",
        "      if X is None or y is None:\n",
        "        raise ValueError('If \"read_data\" is False, X and y should be provided')\n",
        "    if self.debug: print('Preparing data...')\n",
        "    # Get train, validation and test data if provided\n",
        "    if train_val_test_data:\n",
        "      if self.test_size:\n",
        "        X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_data\n",
        "      else:\n",
        "        X_train, X_val, y_train, y_val = train_val_test_data\n",
        "    else:\n",
        "      # Split data into train, validation and test\n",
        "      tint = type(self.test_size) == int\n",
        "      vint = type(self.val_size) == int\n",
        "      if tint and vint:\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = self.val_size, shuffle = self.shuffle)\n",
        "        if self.test_size:\n",
        "          X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = self.test_size, shuffle = self.shuffle)\n",
        "      elif (tint and (not vint)) or ((not tint) and vint):\n",
        "        raise ValueError('test_size and val_size shoud both be integers or both be floats')\n",
        "      else:\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = self.val_size, shuffle = self.shuffle)\n",
        "        if self.test_size:\n",
        "          X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = self.test_size/(1 - self.val_size), shuffle = self.shuffle)\n",
        "      self.num_frames = X_train.shape[1]\n",
        "      # Apply transformation to data\n",
        "      if self.transform:\n",
        "        if self.test_size: \n",
        "          (X_train, y_train), (X_val, y_val), (X_test, y_test) = [applyTransform(X = i, y = j, transform = self.transform) \n",
        "                                                                  for i, j in [(X_train, y_train), (X_val, y_val), (X_test, y_test)]]\n",
        "        else: \n",
        "          (X_train, y_train), (X_val, y_val) = [applyTransform(X = i, y = j, transform = self.transform) \n",
        "                                                                  for i, j in [(X_train, y_train), (X_val, y_val)]]\n",
        "      self.seq_len = X_val.size(1)\n",
        "    # Save train, validation and test tensors\n",
        "    if self.test_size: self.train_val_test_data = [X_train, X_val, X_test, y_train, y_val, y_test]\n",
        "    else: self.train_val_test_data = [X_train, X_val, y_train, y_val]\n",
        "    if self.debug:\n",
        "      if self.test_size: print(f'Train/val/test data shapes:\\n{X_train.size()}, {X_val.size()}, {X_test.size()}\\n{y_train.size()}, {y_val.size()}, {y_test.size()}\\n')\n",
        "      else: print(f'Train/val data shapes:\\n{X_train.size()}, {X_val.size()}\\n{y_train.size()}, {y_val.size()}\\n')\n",
        "    if self.test_size:\n",
        "      return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "    else:\n",
        "      return X_train, X_val, y_train, y_val\n",
        "\n",
        "  def createDataloaders(self, batch_size, shuffle, read_data = False, X = None, y = None, train_val_test_data = None):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    batch_size: int\n",
        "      Batch size for DataLoader\n",
        "    shuffle: bool\n",
        "      If True, shuffle batch data each iteration\n",
        "    read_data: bool, optional\n",
        "      If True, read data from .mat files. Else, read from X and y parameters. Ignored if train_val_test_data is not None. Default: False\n",
        "    X: bool, optional\n",
        "      Features array. Ignored if read_data or train_val_test_data are True. Default: None\n",
        "    y: bool, optional\n",
        "      Labels array. Ignored if read_data or train_val_test_data are True. Default: None\n",
        "    train_val_test_data: list, optional\n",
        "      List with arrays train, test and validation arrays, with format [X_train, X_val, X_test, y_train, y_val, y_test], if\n",
        "      using test data, else [X_train, X_val, y_train, y_val]\n",
        "\n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "    train_dataloader: torch.utils.data.DataLoader\n",
        "      Pytorch train data loader\n",
        "    val_dataloader: torch.utils.data.DataLoader\n",
        "      Pytorch validation data loader\n",
        "    test_dataloader: torch.utils.data.DataLoader\n",
        "      Pytorch test data loader, only if using test data\n",
        "    '''\n",
        "    # Retrieve train, validation and test data\n",
        "    if self.test_size:\n",
        "      X_train, X_val, X_test, y_train, y_val, y_test = self.dataPreparation(read_data, X, y, train_val_test_data)\n",
        "      self.X_train, self.X_val, self.X_test = X_train, X_val, X_test\n",
        "      self.y_train, self.y_val, self.y_test = y_train, y_val, y_test\n",
        "    else:\n",
        "      X_train, X_val, y_train, y_val = self.dataPreparation(read_data, X, y, train_val_test_data)\n",
        "      self.X_train, self.X_val = X_train, X_val\n",
        "      self.y_train, self.y_val = y_train, y_val\n",
        "    if self.debug: print('Creating dataloaders...')\n",
        "    # Generate dataloaders\n",
        "    train_dataset = DatasetAVQ(X_train, y_train)\n",
        "    val_dataset = DatasetAVQ(X_val, y_val)\n",
        "    if self.test_size: test_dataset = DatasetAVQ(X_test, y_test)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = shuffle)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = shuffle)\n",
        "    if self.test_size: test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = shuffle)\n",
        "    if self.debug: print('Dataloaders created!')\n",
        "    if self.debug:\n",
        "      if self.test_size: print(f'Dataloaders sizes:\\n{len(train_dataloader)}, {len(val_dataloader)}, {len(test_dataloader)}')\n",
        "      else: print(f'Dataloaders sizes:\\n{len(train_dataloader)}, {len(val_dataloader)}')\n",
        "    if self.test_size: return train_dataloader, val_dataloader, test_dataloader\n",
        "    else: return train_dataloader, val_dataloader"
      ],
      "metadata": {
        "id": "HWE1JuW3QkFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Auxiliar functions\n",
        "\n",
        "def filterDict(dictionary, keys):\n",
        "  '''\n",
        "  Filter a dictionary by list of keys\n",
        "\n",
        "  Parameters:\n",
        "  -----------------------------------\n",
        "  dictionary: dict\n",
        "    Dictionary to filter\n",
        "  keys: list\n",
        "    List of keys to keep in dictionary\n",
        "\n",
        "  Returns:\n",
        "  -----------------------------------\n",
        "  dict2: dict\n",
        "    Dictionary with filtered keys\n",
        "    '''\n",
        "  dict2 = {k: {k2: round(v2, 4) for k2, v2 in v.items()} if type(v) == dict else v for k, v in dictionary.items() if k in keys}\n",
        "  return dict2\n",
        "\n",
        "def cleanDir(path):\n",
        "  '''\n",
        "  Create an empty directory\n",
        "\n",
        "  Parameters:\n",
        "  -----------------------------------\n",
        "  path: str\n",
        "    Path to empty directory. If path exists, the directory is deleted and recreated with no contents on it.\n",
        "    '''\n",
        "  if os.path.isdir(path):\n",
        "    shutil.rmtree(path)\n",
        "  os.mkdir(path)\n",
        "\n",
        "def save_object(obj, filename):\n",
        "  '''\n",
        "  Save a python object as a pickle file\n",
        "\n",
        "  Parameters:\n",
        "  -----------------------------------\n",
        "  obj: any python object\n",
        "    Python object to pickle\n",
        "  filename: str\n",
        "    Path to saved pickle file\n",
        "    '''\n",
        "  with open(filename, 'wb') as outp:\n",
        "    pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_object(filename):\n",
        "  '''\n",
        "  Load a python object from a pickle file\n",
        "\n",
        "  Parameters:\n",
        "  -----------------------------------\n",
        "  filename: str\n",
        "    Path to pickle file\n",
        "  '''\n",
        "  with open(filename, 'rb') as f:\n",
        "    obj = pickle.load(f)\n",
        "  return obj\n",
        "\n",
        "def elapsedTime(t0, t1):\n",
        "  '''\n",
        "  Print elapsed time\n",
        "\n",
        "  Parameters:\n",
        "  -----------------------------------\n",
        "  t0: time.time\n",
        "    Initial time\n",
        "  t1: time.time\n",
        "    Final time\n",
        "  \n",
        "  Returns:\n",
        "  -----------------------------------\n",
        "  String with elapsed time in minutes and seconds\n",
        "  '''\n",
        "  m, s = divmod(int(t1 - t0), 60)\n",
        "  return f'{m}m{s}s'"
      ],
      "metadata": {
        "id": "30g40GWxEcAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "kz4ag3heSKfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Encoding"
      ],
      "metadata": {
        "id": "rpWUZZ1HI8oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    '''\n",
        "    Transformer Positional Encoding implementation (from https://pytorch.org/tutorials/beginner/transformer_tutorial.html)\n",
        "    '''\n",
        "  def __init__(self, d_model, dropout = 0.1, max_len = 20000):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    d_model: int\n",
        "      Dimension of model's embedding\n",
        "    dropout: float\n",
        "      Dropout value\n",
        "    max_len: int\n",
        "      Maximum length of input sequence\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    position = torch.arange(max_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "    pe = torch.zeros(max_len, 1, d_model)\n",
        "    pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    x: torch.Tensor\n",
        "      Input embedding tensor\n",
        "\n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "      Embedding with positional encoding\n",
        "    '''\n",
        "    x = x + self.pe[:x.size(0)]\n",
        "    return self.dropout(x)"
      ],
      "metadata": {
        "id": "BLFAg3Fct9yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Model\n",
        "4 different models were trained:\n",
        "\n",
        "1. Classification for sample prediction (CS): The model is trained as a classification problem,\n",
        "assigning class probabilities to each AV sample, processing the output probabilities to make\n",
        "predictions, and averaging the predictions of all AV samples of the video.\n",
        "2. Classification for video prediction (CV): The model is trained as a classification problem,\n",
        "predicting the quality of the whole video as a single target score.\n",
        "3. Regression for sample prediction (RS): The model is trained as a regression problem, pre\u0002dicting the quality of each AV sample and averaging the predictions of all AV samples of\n",
        "the video.\n",
        "4. Regression for video prediction (RV): The model is trained as a regression problem, predict\u0002ing the quality of the whole video as a single target score."
      ],
      "metadata": {
        "id": "z6M5Ydrg67PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CV\n",
        "# Input (bs, seq_len, num_feat) --> Embedding (bs, seq_len, embdim) --> Encoder (bs, seq_len, embdim) --> \n",
        "# --> LinearMap (bs, seq_len, 1) --> Squeeze (bs, seq_len) --> Decoder (bs, num_classes)\n",
        "\n",
        "# CS\n",
        "# Input (bs_smpl, num_feat, 1) --> Embedding (bs_smpl, num_feat, embdim) --> Encoder (bs_smpl, num_feat, embdim) --> \n",
        "# --> LinearMap (bs_smpl, num_feat, 1) --> Squeeze (bs_smpl, num_feat) --> Decoder (bs_smpl, num_classes)\n",
        "\n",
        "# RV\n",
        "# Input (bs, seq_len, num_feat) --> Embedding (bs, seq_len, embdim) --> Encoder (bs, seq_len, embdim) --> \n",
        "# --> LinearMap (bs, seq_len, 1) --> Squeeze (bs, seq_len) --> Decoder (bs, 1)\n",
        "\n",
        "# RS\n",
        "# Input (bs_smpl, num_feat, 1) --> Embedding (bs_smpl, num_feat, embdim) --> Encoder (bs_smpl, num_feat, embdim) --> \n",
        "# --> LinearMap (bs_smpl, num_feat, 1) --> Squeeze (bs_smpl, num_feat) --> Decoder (bs_smpl, 1)\n"
      ],
      "metadata": {
        "id": "Q-of2LW07I1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AVQTransformer(nn.Module):\n",
        "  '''\n",
        "  Transformer for AVQA Pytorch model implementation\n",
        "  '''\n",
        "  def __init__(self, clf, framePred, emb_dim, seq_len, num_features, nhead, d_hid,\n",
        "                nlayers, num_classes = 4, emb_activ = nn.GELU, linear_activ = nn.GELU, dropout = 0.2, batch_first = True):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    clf: bool\n",
        "      If True, model is for classification (CV and CS). Else, model is for regression (RV and RS).\n",
        "    framePred: bool\n",
        "      If True, model is for sample prediction (RS and CS). Else, model is for video prediction (CV and RV).\n",
        "    emb_dim: int\n",
        "      Dimension of embedding\n",
        "    seq_len: int\n",
        "      Length of input sequence\n",
        "    num_features: int\n",
        "      Number of features on input data\n",
        "    nhead: int\n",
        "      Number of attention heads\n",
        "    d_hid: int\n",
        "      Dimension of the hidden FC FFN\n",
        "    nlayers: int\n",
        "      Number of encoder layers stacked in series\n",
        "    num_classes: int, optional\n",
        "      Number of classes for classification. Ignored if clf is False. Default: 4\n",
        "    emb_activ: torch.nn activation function, optional\n",
        "      Activation function for embedding linear layer. Default: torch.nn.GELU\n",
        "    linear_activ: torch.nn activation function, optional\n",
        "      Activation function for linear mapping layer. Default: torch.nn.GELU\n",
        "    dropout: float, optional\n",
        "      Dropout for positional encoding and Transformer encoder. Default: 0.2\n",
        "    batch_first: bool, optional\n",
        "      If True (default), consider first dimension of input tensor as batch size. Else, second dimension is batch size.\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.emb_dim = emb_dim\n",
        "    embdim1 = 1 if framePred else num_features\n",
        "    self.embedding = nn.Linear(embdim1, emb_dim)\n",
        "    self.activ1 = emb_activ() if emb_activ else None\n",
        "    self.pos_encoder = PositionalEncoding(emb_dim, dropout)\n",
        "    encoder_layers = TransformerEncoderLayer(emb_dim, nhead, d_hid, dropout, batch_first = batch_first)\n",
        "    self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "    self.linearmap = nn.Linear(emb_dim, 1)\n",
        "    self.activ2 = linear_activ() if linear_activ else None\n",
        "    dim1 = num_features if framePred else seq_len\n",
        "    self.decoder = nn.Linear(dim1, num_classes)\n",
        "\n",
        "  def forward(self, src, src_mask = None, debug = False):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    src: torch.Tensor\n",
        "      Input tensor to the model\n",
        "    src_mask: torch.Tensor, optional\n",
        "      Tensor for masking input. If None (default), no masking is applied\n",
        "    debug: bool, optional\n",
        "      If True, print dimensions of the outputs of each layer after the first batch of the first epoch. Default: False\n",
        "    \n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "    output: torch.Tensor\n",
        "      Output of the model\n",
        "    '''\n",
        "    if debug: print(f'\\nInput shape: {src.size()}')\n",
        "    bs = src.size(0)\n",
        "    # Embedding\n",
        "    src = self.embedding(src) * math.sqrt(self.emb_dim)\n",
        "    if self.activ1: src = self.activ1(src)\n",
        "    if debug: print(f'Embedding output shape: {src.size()}')\n",
        "    # Positional Encoding\n",
        "    src = self.pos_encoder(src)\n",
        "    if debug: print(f'Positional Encoder output shape: {src.size()}')\n",
        "    # Encoder\n",
        "    src = self.transformer_encoder(src, src_mask)\n",
        "    if debug: print(f'Encoder output shape: {src.size()}')\n",
        "    # Linear Mapping\n",
        "    src = self.linearmap(src)\n",
        "    if self.activ2: src = self.activ2(src)\n",
        "    src = src.squeeze(-1)\n",
        "    if debug: print(f'Linear mapping output shape: {src.size()}')\n",
        "    # Decoder\n",
        "    output = self.decoder(src)\n",
        "    output = output.squeeze(-1) if bs == 1 else output.squeeze()\n",
        "    if debug: print(f'Model output shape: {output.size()}')\n",
        "    return output"
      ],
      "metadata": {
        "id": "y_tvmhaDcuoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance metrics"
      ],
      "metadata": {
        "id": "1eecBuHTECoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "class RMSE(nn.Module):\n",
        "    '''\n",
        "    RMSE metric calculation\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        \n",
        "    def forward(self, predictions, target):\n",
        "        '''\n",
        "        Parameters:\n",
        "        -----------------------------------\n",
        "        predictions: torch.Tensor\n",
        "          Tensor of predictions\n",
        "        target: torch.Tensor\n",
        "          Tensor of targets\n",
        "        \n",
        "        Returns:\n",
        "        -----------------------------------\n",
        "          RMSE between prediction and target\n",
        "        '''\n",
        "        return torch.sqrt(self.mse(predictions, target))\n",
        "\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "class PearsonCorrelation(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, predictions, target):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    predictions: torch.Tensor\n",
        "      Tensor of predictions\n",
        "    target: torch.Tensor\n",
        "      Tensor of targets\n",
        "    \n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "      PCC between prediction and target\n",
        "    '''\n",
        "    predictions, target = predictions.detach().to('cpu').numpy(), target.detach().to('cpu').numpy()\n",
        "    corr = pearsonr(predictions, target)[0]\n",
        "    # Treat nan values as correlation 0\n",
        "    if corr == np.nan or corr == float('nan') or corr == 'nan' or math.isnan(corr):\n",
        "      corr = 0\n",
        "    return torch.Tensor([corr])\n",
        "\n",
        "class SpearmanCorrelation(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, predictions, target):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    predictions: torch.Tensor\n",
        "      Tensor of predictions\n",
        "    target: torch.Tensor\n",
        "      Tensor of targets\n",
        "    \n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "      SCC between prediction and target\n",
        "    '''\n",
        "    predictions, target = predictions.detach().to('cpu').numpy(), target.detach().to('cpu').numpy()\n",
        "    corr = spearmanr(predictions, target)[0]\n",
        "    # Treat nan values as correlation 0\n",
        "    if corr == np.nan or corr == float('nan') or corr == 'nan' or math.isnan(corr):\n",
        "      corr = 0\n",
        "    return torch.Tensor([corr])"
      ],
      "metadata": {
        "id": "5QjwRQIDEKp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training setup"
      ],
      "metadata": {
        "id": "eewP7ZS0SRaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/val/test epoch functions"
      ],
      "metadata": {
        "id": "migoIOjAIFuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Auxiliary functions\n",
        "def replicateValues(arr, num):\n",
        "    '''\n",
        "    Pre-processing function to replicate quality values for all AV samples of the signal, with a gaussian noise addition\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    arr: np.ndarray\n",
        "      Array with values to be replicated\n",
        "    num: int\n",
        "      Number of times each value is replicated\n",
        "    \n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "      Array with replicated values with gaussian noise addition\n",
        "    '''\n",
        "    sz = len(arr)\n",
        "    out = np.zeros(sz*num)\n",
        "    for i in range(sz):\n",
        "      out[i*num:(i+1)*num] = arr[i]\n",
        "    # Apply gaussian noise in the resultant array\n",
        "    return out + np.random.normal(0, 0.1, out.shape)\n",
        "\n",
        "def checkCUDAusage():\n",
        "  '''\n",
        "  Function to check CUDA memory usage in the moment\n",
        "  '''\n",
        "  usage = {'allocated': round(torch.cuda.memory_allocated(0)/1024/1024/1024, 5),\n",
        "  'reserved': round(torch.cuda.memory_reserved(0)/1024/1024/1024, 5),\n",
        "  'max_reserved': round(torch.cuda.max_memory_reserved(0)/1024/1024/1024, 5)}\n",
        "  return usage"
      ],
      "metadata": {
        "id": "2BUHXx-1eezU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def outputProcessing(outputs, seq_len, clf = True, framePred = False):\n",
        "  '''\n",
        "    Function to process output of Transformer model\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    outputs: torch.Tensor\n",
        "      Output of the Transformer model\n",
        "    seq_len: int\n",
        "      Length of the output\n",
        "    clf: bool, optional\n",
        "      If True (default), treat as classification (CV and CS) output. Else, treat as regression (RV and RS) output.\n",
        "    framePred: bool, optional\n",
        "      If True, treat as AV sample prediction (CS and RS) output. Else, treat as video prediction (CV and RV) output.\n",
        "    \n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "    outputs: torch.Tensor\n",
        "      Processed outputs\n",
        "    '''\n",
        "  num_samples = len(outputs)\n",
        "  # If classification, apply softmax and assign prediction value as sum of class index + max probability + 1.\n",
        "  if clf:\n",
        "    predictions = F.softmax(outputs, dim = 1)\n",
        "    probs, idxs = torch.max(predictions, axis = 1)\n",
        "    outputs = probs + idxs + 1\n",
        "  # If sample prediction, get average prediction for every AV sample of each signal\n",
        "  if framePred:\n",
        "    outputs = torch.Tensor(np.array([torch.mean(outputs[i:i + seq_len]).item() for i in range(0, num_samples, seq_len)]))\n",
        "  return outputs"
      ],
      "metadata": {
        "id": "FhPMD0o2-7NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import copy\n",
        "\n",
        "def trainEpoch(model, epoch, train_dl, device, criterion, optimizer, scheduler = None,\n",
        "               clf = True, framePred = True, debug = False, print_CUDA = False, show_progress = True,\n",
        "               **metrics):\n",
        "  '''\n",
        "    Function to perform a training epoch\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    model: torch.nn.Module\n",
        "      Transformer model class\n",
        "    epoch: int\n",
        "      Epoch number\n",
        "    train_dl: torch.utils.data.DataLoader\n",
        "      Train data loader\n",
        "    device: str\n",
        "      Device to train the model on. Either 'cuda' or 'cpu'.\n",
        "    criterion: torch.nn.Module\n",
        "      Loss function of the model (e.g. torch.nn.MSELoss)\n",
        "    optimizer: torch.optim class\n",
        "      Optimizer of the model (e.g. torch.optim.Adam)\n",
        "    scheduler: torch.optim class, optional\n",
        "      Learning rate scheduler (e.g. torch.optim.StepLR)\n",
        "    clf: bool, optional\n",
        "      If True (default), treat as classification (CV and CS) output. If False (default), treat as regression (RV and RS) output.\n",
        "    framePred: bool, optional\n",
        "      If True, treat as AV sample prediction (CS and RS) output. If False (default), treat as video prediction (CV and RV) output.\n",
        "    debug: bool, optional\n",
        "      If True, print debugging. Default: False\n",
        "    print_CUDA: bool, optional\n",
        "      If True, print CUDA memory usage at the end of the epoch. Default: False\n",
        "    show_progress: bool, optional\n",
        "      If True (default), show training progress with tqdm bar.\n",
        "    metrics: list\n",
        "      List of metrics to evaluate during training.\n",
        "    \n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "    totalLoss: list\n",
        "      List with loss values for every batch\n",
        "    totalMetrics: dict\n",
        "      Dictionary {metric: [values]} with the metrics results for every batch.\n",
        "    epochMetrics: dict\n",
        "      Dictionary {metric: value} with the metrics calcularions for the entire epoch.\n",
        "    allOutputs: torch.Tensor\n",
        "      Concatenated outputs of every batch.\n",
        "    allLabels: torch.Tensor\n",
        "      Concatenated labels of every batch.\n",
        "    '''\n",
        "  totalLoss = []\n",
        "  totalMetrics = {i:[] for i in metrics}\n",
        "  allOutputs = torch.tensor([]).to('cpu')\n",
        "  allLabels = torch.tensor([]).to('cpu')\n",
        "  epochMetrics = {}\n",
        "  data_usage = {'allocated': [], 'reserved': [], 'max_reserved': []}\n",
        "  with tqdm(train_dl, unit=\"batch\", disable = not show_progress) as tepoch:\n",
        "    for idx, (inputs, labels) in enumerate(tepoch):\n",
        "      if show_progress: tepoch.set_description(f\"Epoch {epoch + 1} train\")\n",
        "      seq_len = inputs.size(1)\n",
        "      allLabels = torch.cat([allLabels, labels], dim = 0).to('cpu')\n",
        "      if debug: print(f'Labels size: {labels.size()}')\n",
        "      if clf:\n",
        "        # Assign MOS values to classes\n",
        "        target = copy(labels)\n",
        "        # Avoid class confusion when MOS is 5 (class would be 5 even though classes should range from 1 to 4)\n",
        "        target[target == 5] = 4.9999 \n",
        "        target = target.long() - 1\n",
        "        if framePred:\n",
        "          # Replicate values for AV sample prediction\n",
        "          inputs = inputs.reshape(-1, inputs.size(-1), 1)\n",
        "          target = torch.LongTensor(replicateValues(target, seq_len))\n",
        "        else:\n",
        "          target = target.long()\n",
        "      else:\n",
        "        target = copy(labels)\n",
        "        if framePred:\n",
        "          # Replicate values for AV sample prediction\n",
        "          inputs = inputs.reshape(-1, inputs.size(-1), 1)\n",
        "          target = torch.FloatTensor(replicateValues(target, seq_len))\n",
        "      if debug: print(f'Num repetitions: {seq_len}')\n",
        "      if debug: print(f'Target size: {target.size()}\\n')\n",
        "      # Send tensors to cuda\n",
        "      inputs, target = inputs.to(device), target.to(device)\n",
        "      # Training epoch\n",
        "      optimizer.zero_grad()\n",
        "      debug = debug and (idx == 0) and (epoch == 0)\n",
        "      outputs = model(inputs, debug = debug)\n",
        "      loss = criterion(outputs, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # Detach from CUDA to save memory\n",
        "      inputs, labels, loss, outputs, target = [inputs.to('cpu'), labels.to('cpu'), loss.to('cpu'), \n",
        "                                               outputs.to('cpu'), target.to('cpu')]\n",
        "      # Save loss and output values\n",
        "      totalLoss.append(loss.to('cpu').item())\n",
        "      outputs = outputProcessing(outputs = outputs, seq_len = seq_len, clf = clf, framePred = framePred)\n",
        "      if debug: print(f'Outputs processing size: {outputs.size()}')\n",
        "      outputs = outputs.to('cpu')\n",
        "      allOutputs = torch.cat([allOutputs, outputs], dim = 0).to('cpu')\n",
        "      # Show loss/metrics progress bar\n",
        "      if idx == len(train_dl) - 1:\n",
        "        # If end of epoch, calculate mean loss and metrics\n",
        "        avgLoss = np.mean(totalLoss)\n",
        "        metricsVals = {}\n",
        "        for name, metric in metrics.items():\n",
        "          metricValue = metric(allOutputs, allLabels).item()\n",
        "          metricsVals[f'train_{name}'] = metricValue\n",
        "          epochMetrics[name] = metricValue\n",
        "          del metricValue\n",
        "        if show_progress: tepoch.set_postfix(train_loss = avgLoss, **metricsVals)\n",
        "        del metricsVals\n",
        "        del avgLoss\n",
        "      else:\n",
        "        if show_progress: tepoch.set_postfix(train_loss = loss.item())\n",
        "      cuda_usage = checkCUDAusage()\n",
        "      if idx % 10 == 9:\n",
        "        for k,v in cuda_usage.items(): data_usage[k].append(v)\n",
        "      del loss\n",
        "      del outputs\n",
        "      del inputs\n",
        "      del labels\n",
        "      del target\n",
        "      allOutputs.to('cpu')\n",
        "      allLabels.to('cpu')\n",
        "  if print_CUDA:\n",
        "    print(f\"Allocated: {data_usage['allocated']}\")\n",
        "    print(f\"Reserved: {data_usage['reserved']}\")\n",
        "    print(f\"Max reserved: {data_usage['max_reserved']}\")\n",
        "  if scheduler:\n",
        "    scheduler.step()\n",
        "  return totalLoss, totalMetrics, epochMetrics, allOutputs, allLabels\n",
        "\n",
        "def valEpoch(model, epoch, val_dl, device, criterion, clf = True, framePred = True, debug = False, \n",
        "             print_CUDA = False, show_progress = True, **metrics):\n",
        "  '''\n",
        "  Function to perform a validation epoch\n",
        "\n",
        "  Parameters:\n",
        "  -----------------------------------\n",
        "  model: torch.nn.Module\n",
        "    Transformer model class\n",
        "  epoch: int\n",
        "    Epoch number\n",
        "  val_dl: torch.utils.data.DataLoader\n",
        "    Validation data loader\n",
        "  device: str\n",
        "    Device to validate the model on. Either 'cuda' or 'cpu'.\n",
        "  criterion: torch.nn.Module\n",
        "    Loss function of the model (e.g. torch.nn.MSELoss)\n",
        "  clf: bool, optional\n",
        "    If True (default), treat as classification (CV and CS) output. Else, treat as regression (RV and RS) output.\n",
        "  framePred: bool, optional\n",
        "    If True, treat as AV sample prediction (CS and RS) output. Else, treat as video prediction (CV and RV) output.\n",
        "  debug: bool, optional\n",
        "    If True, print debugging. Default: False\n",
        "  print_CUDA: bool, optional\n",
        "    If True, print CUDA memory usage at the end of the epoch. Default: False\n",
        "  show_progress: bool, optional\n",
        "    If True (default), show validation progress with tqdm bar.\n",
        "  metrics: list\n",
        "    List of metrics to evaluate during validation.\n",
        "  \n",
        "  Returns:\n",
        "  -----------------------------------\n",
        "  totalLoss: list\n",
        "    List with loss values for every batch\n",
        "  totalMetrics: dict\n",
        "    Dictionary {metric: [values]} with the metrics results for every batch.\n",
        "  epochMetrics: dict\n",
        "    Dictionary {metric: value} with the metrics calcularions for the entire epoch.\n",
        "  allOutputs: torch.Tensor\n",
        "    Concatenated outputs of every batch.\n",
        "  allLabels: torch.Tensor\n",
        "    Concatenated labels of every batch.\n",
        "  '''\n",
        "  totalLoss = []\n",
        "  totalMetrics = {i:[] for i in metrics}\n",
        "  allOutputs = torch.tensor([])\n",
        "  allLabels = torch.tensor([])\n",
        "  epochMetrics = {}\n",
        "  data_usage = {'allocated': [], 'reserved': [], 'max_reserved': []}\n",
        "  with tqdm(val_dl, unit=\"batch\", disable = not show_progress) as tepoch:\n",
        "    for idx, (inputs, labels) in enumerate(tepoch):\n",
        "      if show_progress: tepoch.set_description(f\"Epoch {epoch + 1} validation\")\n",
        "      seq_len = inputs.size(1)\n",
        "      allLabels = torch.cat([allLabels, labels], dim = 0)\n",
        "      if clf:\n",
        "        # # Assign MOS values to classes\n",
        "        target = copy(labels)\n",
        "        # Avoid class confusion when MOS is 5 (class would be 5 even though classes should range from 1 to 4)\n",
        "        target[target == 5] = 4.9999\n",
        "        target = target.long() - 1\n",
        "        if framePred:\n",
        "          # Replicate values for AV sample prediction\n",
        "          inputs = inputs.reshape(-1, inputs.size(-1), 1)\n",
        "          target = torch.LongTensor(replicateValues(target, seq_len))\n",
        "        else:\n",
        "          target = target.long()\n",
        "      else:\n",
        "        target = copy(labels)\n",
        "        if framePred:\n",
        "          # Replicate values for AV sample prediction\n",
        "          inputs = inputs.reshape(-1, inputs.size(-1), 1)\n",
        "          target = torch.FloatTensor(replicateValues(target, seq_len))\n",
        "      # Send tensors to cuda\n",
        "      inputs, target = inputs.to(device), target.to(device)\n",
        "      # Evaluation process\n",
        "      debug = debug and (idx == 0) and (epoch == 0)\n",
        "      outputs = model(inputs, debug = debug)\n",
        "      loss = criterion(outputs, target)\n",
        "      # Detach from CUDA to save memory\n",
        "      inputs, labels, loss, outputs, target = [inputs.to('cpu'), labels.to('cpu'), loss.to('cpu'), \n",
        "                                               outputs.to('cpu'), target.to('cpu')]\n",
        "      totalLoss.append(loss.item())\n",
        "      # Show evaluation progress bar\n",
        "      # Save loss and output values\n",
        "      outputs = outputProcessing(outputs = outputs, seq_len = seq_len, clf = clf, framePred = framePred)\n",
        "      if debug: print(f'Outputs processing size: {outputs.size()}')\n",
        "      outputs = outputs.to('cpu')\n",
        "      allOutputs = torch.cat([allOutputs, outputs], dim = 0).to('cpu')\n",
        "      if idx == len(val_dl) - 1:\n",
        "        # If end of epoch, calculate mean loss and metrics\n",
        "        avgValLoss = np.mean(totalLoss)\n",
        "        metricsVals = {}\n",
        "        for name, metric in metrics.items():\n",
        "          metricValue = metric(allOutputs, allLabels).to('cpu').item()\n",
        "          metricsVals[f'val_{name}'] = metricValue\n",
        "          epochMetrics[name] = metricValue\n",
        "          del metricValue\n",
        "        if show_progress: tepoch.set_postfix(Val_Loss = avgValLoss, **metricsVals)\n",
        "        del avgValLoss\n",
        "        del metricsVals\n",
        "      else:\n",
        "        if show_progress: tepoch.set_postfix(val_loss = loss.item())\n",
        "      cuda_usage = checkCUDAusage()\n",
        "      if idx % 10 == 9:\n",
        "        for k,v in cuda_usage.items(): data_usage[k].append(v)\n",
        "      del loss\n",
        "      del outputs\n",
        "      del inputs\n",
        "      del labels\n",
        "      del target\n",
        "      allOutputs.to('cpu')\n",
        "      allLabels.to('cpu')\n",
        "  if print_CUDA:\n",
        "    print(f\"Allocated: {data_usage['allocated']}\")\n",
        "    print(f\"Reserved: {data_usage['reserved']}\")\n",
        "    print(f\"Max reserved: {data_usage['max_reserved']}\")\n",
        "  return totalLoss, totalMetrics, epochMetrics, allOutputs, allLabels\n",
        "\n"
      ],
      "metadata": {
        "id": "TuWnlMu9ILkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Trainer"
      ],
      "metadata": {
        "id": "TMogSsQj_Gp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PytorchTrainer():\n",
        "  ''' Train a Pyrotch model'''\n",
        "  def __init__(self):\n",
        "    self.epochMetrics = {'Train': [], 'Val': []}\n",
        "  \n",
        "  def train_validate(self, model, epochs, train_dl, val_dl, device, criterion, optimizer, savePath, \n",
        "                     scheduler = None, clf = False, framePred = False, debug = False, \n",
        "                     saveBest = 'PCC', highestBest = True, print_CUDA = False, show_progress = True,\n",
        "                     **metrics):\n",
        "    '''\n",
        "    Function to perform training and validation of the model\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    model: torch.nn.Module\n",
        "      Transformer model class\n",
        "    epochs: int\n",
        "      Number of epochs\n",
        "    train_dl: torch.utils.data.DataLoader\n",
        "      Train data loader\n",
        "    val_dl: torch.utils.data.DataLoader\n",
        "      Validation data loader\n",
        "    device: str\n",
        "      Device to train and validate the model on. Either 'cuda' or 'cpu'.\n",
        "    criterion: torch.nn.Module\n",
        "      Loss function of the model (e.g. torch.nn.MSELoss)\n",
        "    optimizer: torch.optim class\n",
        "      Optimizer of the model (e.g. torch.optim.Adam)\n",
        "    savePath: str\n",
        "      Path to save results of training and validation\n",
        "    scheduler: torch.optim class, optional\n",
        "      Learning rate scheduler (e.g. torch.optim.StepLR)\n",
        "    clf: bool, optional\n",
        "      If True (default), treat as classification (CV and CS) output. Else, treat as regression (RV and RS) output.\n",
        "    framePred: bool, optional\n",
        "      If True, treat as AV sample prediction (CS and RS) output. Else, treat as video prediction (CV and RV) output.\n",
        "    debug: bool, optional\n",
        "      If True, print debugging. Default: False\n",
        "    saveBest: str, optional\n",
        "      Metric to consider when evaluating best model. Either 'PCC' (default), 'SCC' or 'RMSE'.\n",
        "    highestBest: bool, optional\n",
        "      If True (default), model is considered best if metric (defined in saveBest) is the highest. If False, if its the lowest.\n",
        "    print_CUDA: bool, optional\n",
        "      If True, print CUDA memory usage at the end of the epoch. Default: False\n",
        "    show_progress: bool, optional\n",
        "      If True (default), show training and validation progress with tqdm bar.\n",
        "    metrics: list\n",
        "      List of metrics to evaluate during training and validation.\n",
        "    '''\n",
        "    # Initialize best metric value\n",
        "    if highestBest:\n",
        "      best_metric = float('-inf')\n",
        "    else:\n",
        "      best_metric = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "      # Train and validate model, saving the results\n",
        "      t0 = time()\n",
        "      model.train()\n",
        "      train_loss, train_metrics, epoch_train_metrics, train_outputs, train_labels = trainEpoch(model, epoch, train_dl, device, \n",
        "                                                                                               criterion, optimizer, scheduler, \n",
        "                                                                                               clf, framePred, debug, \n",
        "                                                                                               print_CUDA, show_progress, \n",
        "                                                                                               **metrics)\n",
        "      torch.cuda.empty_cache() \n",
        "      self.epochMetrics['Train'].append(epoch_train_metrics)\n",
        "      model.eval()\n",
        "      val_loss, val_metrics, epoch_val_metrics, val_outputs, val_labels = valEpoch(model, epoch, val_dl, device, criterion, \n",
        "                                                                                  clf, framePred, debug, print_CUDA, \n",
        "                                                                                   show_progress, **metrics)\n",
        "      \n",
        "      torch.cuda.empty_cache()\n",
        "      # Check if resultant metric is the best so far\n",
        "      checkMetric = epoch_val_metrics[saveBest]\n",
        "      isBest = (highestBest and checkMetric >= best_metric) or ((not highestBest) and checkMetric <= best_metric)\n",
        "      # If its best metric, update best_metric and its state dictionary\n",
        "      if isBest:\n",
        "        best_metric = epoch_val_metrics[saveBest]\n",
        "        self.best_state_dict = {\n",
        "              'epoch': epoch+1,\n",
        "              # 'model_state_dict': {k: v.detach().to('cpu') for k, v in model.state_dict().items()},\n",
        "              'epoch_val_metrics': epoch_val_metrics,\n",
        "              'epoch_train_metrics': epoch_train_metrics\n",
        "              }\n",
        "        torch.save(self.best_state_dict, os.path.join(savePath, 'best.pt'))\n",
        "      self.epochMetrics['Val'].append(epoch_val_metrics)\n",
        "      if print_CUDA:\n",
        "        print('='*200)\n",
        "        print(\"Epoch allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
        "        print(\"Epoch reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
        "        print(\"Epoch memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
        "        print('='*200)\n",
        "        print('='*200)\n",
        "      t1 = time()\n",
        "      if (not show_progress) and (epoch == 0): \n",
        "        print(f'Time for 1st epoch: {elapsedTime(t0, t1)}')\n",
        "        print(f'Estimated time for {epochs} epochs: {elapsedTime(epochs*t0, epochs*t1)}')\n",
        "    self.last_state_dict = {\n",
        "              'epoch': epoch+1,\n",
        "              # 'model_state_dict': {k: v.detach().to('cpu') for k, v in model.state_dict().items()},\n",
        "              'epoch_val_metrics': epoch_val_metrics,\n",
        "              'epoch_train_metrics': epoch_train_metrics\n",
        "              }\n",
        "    torch.save(self.last_state_dict, os.path.join(savePath, 'last.pt'))\n"
      ],
      "metadata": {
        "id": "r_QZp_zOKBeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Progress plot functions"
      ],
      "metadata": {
        "id": "vUejc9OPwngv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_epoch_metrics(listEpochMetrics, metrics, prefixs, colors, plot_train = True, plot_val = True, \n",
        "                       num_div = 8, **kwargs):\n",
        "  '''\n",
        "    Plot metrics results per epoch\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    listEpochMetrics: list\n",
        "      List contaning the state dictionaries to plot.\n",
        "    metrics: dict\n",
        "      Dictionary {metric name: metric class}\n",
        "    prefixs: list\n",
        "      List with names of models being compared\n",
        "    colors: list\n",
        "      List of colors for every line in plot, sequentially\n",
        "    plot_train: bool, optional\n",
        "      If True (default), plot training metrics\n",
        "    plot_val: bool, optional\n",
        "      If True (default), plot validation metrics\n",
        "    num_div: int, optional\n",
        "      Number of y-axis points. Default: 8\n",
        "    kwargs: dict\n",
        "      Optional arguments for plot.\n",
        "    '''\n",
        "  assert plot_train or plot_val, 'At leat one of plot_train or plot_val should be set to True'\n",
        "  fig, ax = plt.subplots(len(metrics), 1, figsize = kwargs.get('figsize', (8, 8)))\n",
        "  if len(metrics) == 1:\n",
        "    iterator = [(list(metrics.keys())[0], ax)]\n",
        "  else:\n",
        "    iterator = [(m, a) for m, a in zip(list(metrics.keys()), ax)]\n",
        "  for metric, axis in iterator:\n",
        "    allYs = np.array([])\n",
        "    allXs = np.array([])\n",
        "    for idx, epochMetrics in enumerate(listEpochMetrics):\n",
        "      # print(f'Ep Metrics: {epochMetrics}')\n",
        "      y = [i[metric] for i in epochMetrics['Train']]\n",
        "      val_y = [i[metric] for i in epochMetrics['Val']]\n",
        "      x = np.arange(1, len(y) + 1)\n",
        "      val_x = np.arange(1, len(val_y) + 1)\n",
        "\n",
        "      if plot_train:\n",
        "        axis.plot(x, y, color = colors[idx], label = f'{prefixs[idx]} Train', \n",
        "                  linestyle = kwargs.get('train_linestyle', 'solid'))\n",
        "        allYs = np.concatenate([allYs, y])\n",
        "        allXs = np.concatenate([allXs, x])\n",
        "      if plot_val:\n",
        "        axis.plot(val_x, val_y, color = colors[idx], label = f'{prefixs[idx]} Val', \n",
        "                  linestyle = kwargs.get('val_linestyle', 'dashed'))\n",
        "        allXs = np.concatenate([allXs, val_x])\n",
        "        allYs = np.concatenate([allYs, val_y])\n",
        "    step = (1/num_div)*(max(allYs) - min(allYs))\n",
        "    low = min(allYs) - step/2\n",
        "    high = max(allYs) + step/2\n",
        "    ticks = np.arange(low, high, step)\n",
        "    # if metric == 'RMSE': print(f'{metric}\\nallYs: {allYs}\\nmin: {min(allYs)}\\nmax: {max(allYs)}\\nlow: {low}\\nhigh: {high}\\nstep: {step}\\nticks: {ticks}')\n",
        "    axis.set_title(f'{metric} per epoch')\n",
        "    axis.set_xlabel('Epoch')\n",
        "    axis.set_ylabel(metric)\n",
        "    xstep = max(allXs)//10 if max(allXs) > 10 else 1\n",
        "    axis.set_xticks(np.arange(1, max(allXs), xstep))\n",
        "    if f'{metric}_xticks' in kwargs:\n",
        "      axis.set_xticks(kwargs[f'{metric}_xticks'])\n",
        "    elif 'xticks' in kwargs:\n",
        "      axis.set_xticks(kwargs['xticks'])\n",
        "    if f'{metric}_rotationx' in kwargs:\n",
        "      axis.set_xticklabels(axis.get_xticks(), rotation = kwargs[f'{metric}_rotationx'])\n",
        "    elif 'rotationx' in kwargs:\n",
        "      axis.set_xticklabels(axis.get_xticks(), rotation = kwargs['rotationx'])\n",
        "    if f'{metric}_yticks' in kwargs:\n",
        "      axis.set_yticks(kwargs[f'{metric}_yticks'])\n",
        "    elif 'yticks' in kwargs:\n",
        "      axis.set_yticks(kwargs['yticks'])\n",
        "    else:\n",
        "      axis.set_yticks(ticks)\n",
        "      axis.set_yticklabels([round(i, 2) for i in ticks])\n",
        "    if f'{metric}_rotationy' in kwargs:\n",
        "      axis.set_yticklabels(axis.get_yticks(), rotation = kwargs[f'{metric}_rotationy'])\n",
        "    elif 'rotationy' in kwargs:\n",
        "      axis.set_yticklabels(axis.get_yticks(), rotation = kwargs['rotationy'])\n",
        "    axis.legend(loc = kwargs.get('legendloc', 'best'))\n",
        "    if kwargs.get(f'{metric}_grid', False):\n",
        "      axis.grid()\n",
        "    if kwargs.get('suptitle', False):\n",
        "      plt.suptitle(kwargs['suptitle'])\n",
        "  plt.tight_layout(4)\n",
        "  if kwargs.get('savePath', False):\n",
        "    plt.savefig(kwargs['savePath'])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "grWdjbev95gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training data setup"
      ],
      "metadata": {
        "id": "ZF-FeNksgU7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainingDataSetup():\n",
        "  '''Setup data for training'''\n",
        "  def __init__(self, dataParams):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    dataParams: dict\n",
        "      Parameters for data preparation (train_size, val_size, test_size, transform, ...)\n",
        "    '''\n",
        "    self.dataParams = dataParams\n",
        "    self.gotData = False\n",
        "    \n",
        "  def getData(self, X, y, train_val_test_data = None, sampling_rate = 1, plot = False, figsize = (6, 4)):\n",
        "    '''\n",
        "    Function to perform a training epoch\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    X: torch.Tensor\n",
        "      Features tensor\n",
        "    y: torch.Tensor\n",
        "      Labels tensor\n",
        "    train_val_test_data: list, optional\n",
        "      List with arrays train, test and validation arrays, with format [X_train, X_val, X_test, y_train, y_val, y_test], if\n",
        "      using test data, else [X_train, X_val, y_train, y_val]\n",
        "    sampling_rate: int, optional\n",
        "      Rate for downsampling (e.g. for sample_rate=30, only one sample is retained every 30 samples). Default: 1\n",
        "    plot: bool, optional\n",
        "      If True (default), plot labels train and test distribution\n",
        "    figsize: tuple, optional\n",
        "      Figure size of the plotted distribution (only used if plot=True)\n",
        "    '''\n",
        "    assert len(X) == len(y), 'Lengths of X and y should be equal'\n",
        "    params = self.dataParams\n",
        "    train_size, val_size, test_size = [params['train_size'], params['val_size'], \n",
        "                                       params['test_size']]\n",
        "    if not params['allData']:\n",
        "      if params['idxs'] is None:\n",
        "        if not ((type(train_size) == int) and (type(val_size) == int) and (type(test_size) == int)):\n",
        "          raise ValueError('Train, val and test sizes should be integers')\n",
        "        self.idxs = np.random.randint(len(X), size = train_size + val_size + test_size)\n",
        "      else:\n",
        "        self.idxs = params['idxs']\n",
        "      self.X, self.y = X[self.idxs], y[self.idxs]\n",
        "    else:\n",
        "      self.X, self.y = copy(X), copy(y)\n",
        "\n",
        "    self.dataHolder = AVQTransformerData(params['matPath'], params['mosPath'], params['featuresName'], \n",
        "                                          params['val_size'], params['test_size'], params['transform'], \n",
        "                                          params['shuffle'], params['debug'])\n",
        "    if train_val_test_data:\n",
        "      train_val_test_data = [i[:, ::sampling_rate, :] if (i.dim() == 3) else i for i in train_val_test_data]\n",
        "    if params['test_size'] == 0:\n",
        "      self.train_dl, self.val_dl = self.dataHolder.createDataloaders(params['batch_size'], \n",
        "                                                                     params['shuffle'], \n",
        "                                                                     params['read_data'], \n",
        "                                                                     self.X, self.y,\n",
        "                                                                     train_val_test_data)\n",
        "      self.train_dl_smpl, self.val_dl_smpl = self.dataHolder.createDataloaders(params['bs_smpl'], \n",
        "                                                                     params['shuffle'], \n",
        "                                                                     params['read_data'], \n",
        "                                                                     self.X, self.y,\n",
        "                                                                     self.dataHolder.train_val_test_data)\n",
        "    else:\n",
        "      self.train_dl, self.val_dl, self.test_dl = self.dataHolder.createDataloaders(params['batch_size'], \n",
        "                                                                                   params['shuffle'], \n",
        "                                                                                   params['read_data'], \n",
        "                                                                                   self.X, self.y,\n",
        "                                                                                   train_val_test_data)\n",
        "      self.train_dl_smpl, self.val_dl_smpl, self.test_dl_smpl = self.dataHolder.createDataloaders(params['bs_smpl'], \n",
        "                                                                                   params['shuffle'], \n",
        "                                                                                   params['read_data'], \n",
        "                                                                                   self.X, self.y,\n",
        "                                                                                   self.dataHolder.train_val_test_data)\n",
        "    if plot:\n",
        "      self.plotLabelsDistribution(figsize = figsize)\n",
        "    self.gotData = True\n",
        "\n",
        "  def plotLabelsDistribution(self, figsize = (6, 4)):\n",
        "    '''\n",
        "    Function to plot data distribution\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    figsize: tuple, optional\n",
        "      Figure size of the plot\n",
        "    '''\n",
        "    if self.dataParams['test_size'] == 0: fig, ax = plt.subplots(2, 1, figsize = figsize)\n",
        "    else: fig, ax = plt.subplots(3, 1, figsize = figsize)\n",
        "    # Histogram plot of the labels in train and testing\n",
        "    sns.histplot(self.dataHolder.y_train, ax = ax[0])\n",
        "    ax[0].set_title('Train')\n",
        "    sns.histplot(self.dataHolder.y_val, ax = ax[1])\n",
        "    ax[1].set_title('Validation')\n",
        "    if self.dataParams['test_size'] != 0:\n",
        "      sns.histplot(self.dataHolder.y_test, ax = ax[2])\n",
        "      ax[2].set_title('Test')\n",
        "    plt.tight_layout(2)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "EiubwBadfP8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training setup"
      ],
      "metadata": {
        "id": "c93-e2yhaThd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainingSetup(TrainingDataSetup):\n",
        "  '''Setup training for the 4 model configurations'''\n",
        "  def __init__(self, modelVidParams, modelSmplParams, dataParams, metrics, device):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    modelVidParams: dict\n",
        "      Parameters of the Transformer model for video prediction (CV and RV).\n",
        "    modelSmplParams: dict\n",
        "      Parameters of the Transformer model for sample prediction (CS and RS).\n",
        "    dataParams: dict\n",
        "      Parameters for dataloaders creation\n",
        "    metrics: dict\n",
        "      Dictionary {metric: metric class} for metrics used in evaluation\n",
        "    device: str\n",
        "      Device to train the model on. Either 'cuda' or 'cpu'.\n",
        "    '''\n",
        "    super().__init__(dataParams)\n",
        "    self.modelVidParams = modelVidParams\n",
        "    self.modelSmplParams = modelSmplParams\n",
        "    self.device = device\n",
        "    self.metrics = metrics\n",
        "    self.createModels()\n",
        "\n",
        "  def createModels(self):\n",
        "    '''Create the CV, CS, RV and RS models'''\n",
        "    self.CVFitted, self.CSFitted, self.RVFitted, self.RSFitted = [False, False, False, False]\n",
        "    self.CVParams = {'clf': True, 'framePred': False, 'num_classes': 4}\n",
        "    self.CVParams.update(self.modelVidParams)\n",
        "    self.modelCV = AVQTransformer(**self.CVParams)\n",
        "    self.CSParams = {'clf': True, 'framePred': True, 'num_classes': 4}\n",
        "    self.CSParams.update(self.modelSmplParams)\n",
        "    self.modelCS = AVQTransformer(**self.CSParams)\n",
        "    self.RVParams = {'clf': False, 'framePred': False, 'num_classes': 1}\n",
        "    self.RVParams.update(self.modelVidParams)\n",
        "    self.modelRV = AVQTransformer(**self.RVParams)\n",
        "    self.RSParams = {'clf': False, 'framePred': True, 'num_classes': 1}\n",
        "    self.RSParams.update(self.modelSmplParams)\n",
        "    self.modelRS = AVQTransformer(**self.RSParams)\n",
        "\n",
        "  def train_val_dl(self, framePred):\n",
        "    '''\n",
        "    Create training and validation data loaders\n",
        "    \n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    framePred: bool\n",
        "      If True, treat as AV sample prediction (CS and RS). If False, as video prediction (CV and RV)\n",
        "    \n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "    self.train_dl: torch.data.utils.DataLoader\n",
        "      Train data loader\n",
        "    self.val_dl: torch.data.utils.DataLoader\n",
        "      Validation data loader\n",
        "    '''\n",
        "    if not self.gotData: raise ValueError('Data not loaded yet')\n",
        "    if framePred: return self.train_dl_smpl, self.val_dl_smpl\n",
        "    else: return self.train_dl, self.val_dl\n",
        "\n",
        "  def setupTrainer(self, model, criterion, scheduler = None, schedulerParams = None, optimizerLR = 1e-3):\n",
        "    '''\n",
        "    Setup optimizer and scheduler for model\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    model: torch.nn.Module\n",
        "      Transformer model class\n",
        "    criterion: torch.nn.Module\n",
        "      Loss function of the model (e.g. torch.nn.MSELoss)\n",
        "    scheduler: torch.optim class, optional\n",
        "      Learning rate scheduler (e.g. torch.optim.StepLR)\n",
        "    schedulerParams: dict\n",
        "      Parameters of the scheduler\n",
        "    optimizerLR: float\n",
        "      Initial learning rate of the optimizer\n",
        "\n",
        "    Returns:\n",
        "    -----------------------------------\n",
        "    optimizer: torch.optim class\n",
        "      Optimizer of the model\n",
        "    scheduler: torch.optim class, optional\n",
        "      Learning rate scheduler of the model\n",
        "    '''\n",
        "    model.to(self.device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = optimizerLR)\n",
        "    if scheduler:\n",
        "      if not schedulerParams:\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = epochs//5, gamma = 0.5, \n",
        "                                                    verbose = False)\n",
        "      else:\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, **schedulerParams)\n",
        "    return optimizer, scheduler\n",
        "\n",
        "  def CVTrain(self, epochs, savePath, debug = True, scheduler = None, schedulerParams = None,\n",
        "              optimizerLR = 1e-3, saveBest = 'PCC', highestBest = True, print_CUDA = False, \n",
        "              show_progress = True):\n",
        "    '''\n",
        "    Train CV model\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    epochs: int\n",
        "      Number of epochs\n",
        "    savePath: str\n",
        "      Path to save results of training and validation\n",
        "    scheduler: torch.optim class, optional\n",
        "      Learning rate scheduler (e.g. torch.optim.StepLR)\n",
        "    schedulerParams: dict\n",
        "      Parameters of the scheduler\n",
        "    optimizerLR: float\n",
        "      Initial learning rate of the optimizer\n",
        "    saveBest: str, optional\n",
        "      Metric to consider when evaluating best model. Either 'PCC' (default), 'SCC' or 'RMSE'.\n",
        "    highestBest: bool, optional\n",
        "      If True (default), model is considered best if metric (defined in saveBest) is the highest. If False, if its the lowest.\n",
        "    print_CUDA: bool, optional\n",
        "      If True, print CUDA memory usage at the end of the epoch. Default: False\n",
        "    show_progress: bool, optional\n",
        "      If True (default), show training and validation progress with tqdm bar.\n",
        "    '''\n",
        "    # Get data loaders\n",
        "    if not self.gotData:\n",
        "      raise ValueError('Data not loaded yet')\n",
        "    train_dl, val_dl = self.train_val_dl(framePred = False)\n",
        "    # Setup loss, optimizer and scheduler\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer, scheduler = self.setupTrainer(self.modelCV, criterion, scheduler, schedulerParams, optimizerLR)\n",
        "    # Train model\n",
        "    self.trainerCV = PytorchTrainer()\n",
        "    self.trainerCV.train_validate(self.modelCV, epochs, train_dl, val_dl, self.device,\n",
        "                                  criterion, optimizer, savePath, scheduler, self.CVParams['clf'], \n",
        "                                  self.CVParams['framePred'], debug, saveBest, highestBest, print_CUDA,\n",
        "                                  show_progress, **self.metrics)\n",
        "\n",
        "  def CSTrain(self, epochs, savePath, debug = True, scheduler = None, schedulerParams = None,\n",
        "              optimizerLR = 1e-3, saveBest = 'PCC', highestBest = True, print_CUDA = False, \n",
        "              show_progress = True):\n",
        "    '''\n",
        "    Train CS model\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    epochs: int\n",
        "      Number of epochs\n",
        "    savePath: str\n",
        "      Path to save results of training and validation\n",
        "    scheduler: torch.optim class, optional\n",
        "      Learning rate scheduler (e.g. torch.optim.StepLR)\n",
        "    schedulerParams: dict\n",
        "      Parameters of the scheduler\n",
        "    optimizerLR: float\n",
        "      Initial learning rate of the optimizer\n",
        "    saveBest: str, optional\n",
        "      Metric to consider when evaluating best model. Either 'PCC' (default), 'SCC' or 'RMSE'.\n",
        "    highestBest: bool, optional\n",
        "      If True (default), model is considered best if metric (defined in saveBest) is the highest. If False, if its the lowest.\n",
        "    print_CUDA: bool, optional\n",
        "      If True, print CUDA memory usage at the end of the epoch. Default: False\n",
        "    show_progress: bool, optional\n",
        "      If True (default), show training and validation progress with tqdm bar.\n",
        "    '''\n",
        "    # Get data loaders\n",
        "    train_dl, val_dl = self.train_val_dl(framePred = True)\n",
        "    # Setup loss, optimizer and scheduler\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer, scheduler = self.setupTrainer(self.modelCS, criterion, scheduler, schedulerParams, optimizerLR)\n",
        "    # Train model\n",
        "    self.trainerCS = PytorchTrainer()\n",
        "    self.trainerCS.train_validate(self.modelCS, epochs, train_dl, val_dl, self.device,\n",
        "                                  criterion, optimizer, savePath, scheduler, self.CSParams['clf'], \n",
        "                                  self.CSParams['framePred'], debug, saveBest, highestBest, print_CUDA,\n",
        "                                  show_progress, **self.metrics)\n",
        "\n",
        "  def RVTrain(self, epochs, savePath, debug = True, scheduler = None, schedulerParams = None,\n",
        "              optimizerLR = 1e-3, saveBest = 'PCC', highestBest = True, print_CUDA = False, \n",
        "              show_progress = True):\n",
        "    '''\n",
        "    Train RV model\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    epochs: int\n",
        "      Number of epochs\n",
        "    savePath: str\n",
        "      Path to save results of training and validation\n",
        "    scheduler: torch.optim class, optional\n",
        "      Learning rate scheduler (e.g. torch.optim.StepLR)\n",
        "    schedulerParams: dict\n",
        "      Parameters of the scheduler\n",
        "    optimizerLR: float\n",
        "      Initial learning rate of the optimizer\n",
        "    saveBest: str, optional\n",
        "      Metric to consider when evaluating best model. Either 'PCC' (default), 'SCC' or 'RMSE'.\n",
        "    highestBest: bool, optional\n",
        "      If True (default), model is considered best if metric (defined in saveBest) is the highest. If False, if its the lowest.\n",
        "    print_CUDA: bool, optional\n",
        "      If True, print CUDA memory usage at the end of the epoch. Default: False\n",
        "    show_progress: bool, optional\n",
        "      If True (default), show training and validation progress with tqdm bar.\n",
        "    '''\n",
        "    # Get data loaders\n",
        "    train_dl, val_dl = self.train_val_dl(framePred = False)\n",
        "    # Setup loss, optimizer and scheduler\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer, scheduler = self.setupTrainer(self.modelRV, criterion, scheduler, schedulerParams, optimizerLR)\n",
        "    # Train model\n",
        "    self.trainerRV = PytorchTrainer()\n",
        "    self.trainerRV.train_validate(self.modelRV, epochs, train_dl, val_dl, self.device,\n",
        "                                  criterion, optimizer, savePath, scheduler, self.RVParams['clf'], \n",
        "                                  self.RVParams['framePred'], debug, saveBest, highestBest, print_CUDA,\n",
        "                                  show_progress, **self.metrics)\n",
        "\n",
        "  def RSTrain(self, epochs, savePath, debug = True, scheduler = None, schedulerParams = None,\n",
        "              optimizerLR = 1e-3, saveBest = 'PCC', highestBest = True, print_CUDA = False, \n",
        "              show_progress = True):\n",
        "    '''\n",
        "    Train RS model\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    epochs: int\n",
        "      Number of epochs\n",
        "    savePath: str\n",
        "      Path to save results of training and validation\n",
        "    scheduler: torch.optim class, optional\n",
        "      Learning rate scheduler (e.g. torch.optim.StepLR)\n",
        "    schedulerParams: dict\n",
        "      Parameters of the scheduler\n",
        "    optimizerLR: float\n",
        "      Initial learning rate of the optimizer\n",
        "    saveBest: str, optional\n",
        "      Metric to consider when evaluating best model. Either 'PCC' (default), 'SCC' or 'RMSE'.\n",
        "    highestBest: bool, optional\n",
        "      If True (default), model is considered best if metric (defined in saveBest) is the highest. If False, if its the lowest.\n",
        "    print_CUDA: bool, optional\n",
        "      If True, print CUDA memory usage at the end of the epoch. Default: False\n",
        "    show_progress: bool, optional\n",
        "      If True (default), show training and validation progress with tqdm bar.\n",
        "    '''\n",
        "    # Get data loaders\n",
        "    train_dl, val_dl = self.train_val_dl(framePred = True)\n",
        "    # Setup loss, optimizer and scheduler\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer, scheduler = self.setupTrainer(self.modelRS, criterion, scheduler, schedulerParams, optimizerLR)\n",
        "    # Train model\n",
        "    self.trainerRS = PytorchTrainer()\n",
        "    self.trainerRS.train_validate(self.modelRS, epochs, train_dl, val_dl, self.device,\n",
        "                                  criterion, optimizer, savePath, scheduler, self.RSParams['clf'], \n",
        "                                  self.RSParams['framePred'], debug, saveBest, highestBest, print_CUDA,\n",
        "                                  show_progress, **self.metrics)\n",
        "  \n",
        "  def train(self, epochs, savePath, debug = True, scheduler = None, schedulerParams = None,\n",
        "            optimizerLR = 1e-3, saveBest = 'PCC', highestBest = True, print_CUDA = False,\n",
        "            saveEpochMetrics = True, show_progress = True):\n",
        "    '''\n",
        "    Train CV, CS, RV and RS models\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    epochs: int\n",
        "      Number of epochs\n",
        "    savePath: str\n",
        "      Path to save results of training and validation\n",
        "    debug: bool, optional\n",
        "      If True (default), show debugging of models' layers output shapes\n",
        "    scheduler: torch.optim class, optional\n",
        "      Learning rate scheduler (e.g. torch.optim.StepLR)\n",
        "    schedulerParams: dict, optional\n",
        "      Parameters of the scheduler\n",
        "    optimizerLR: float\n",
        "      Initial learning rate of the optimizer\n",
        "    saveBest: str, optional\n",
        "      Metric to consider when evaluating best model. Either 'PCC' (default), 'SCC' or 'RMSE'.\n",
        "    highestBest: bool, optional\n",
        "      If True (default), model is considered best if metric (defined in saveBest) is the highest. If False, if its the lowest.\n",
        "    print_CUDA: bool, optional\n",
        "      If True, print CUDA memory usage at the end of the epoch. Default: False\n",
        "    saveEpochMetrics: bool, optional\n",
        "      If True (default), save metrics calculated every epoch to a pickle file (with path defined on savePath)\n",
        "    show_progress: bool, optional\n",
        "      If True (default), show training and validation progress with tqdm bar.\n",
        "    '''\n",
        "    t0 = time()\n",
        "    # Train CV model\n",
        "    print('Training CV')\n",
        "    if show_progress: print('\\n')\n",
        "    CVPath = os.path.join(savePath, 'CVModel/')\n",
        "    cleanDir(CVPath)\n",
        "    self.CVTrain(epochs, CVPath, debug, scheduler, schedulerParams,\n",
        "            optimizerLR, saveBest, highestBest, print_CUDA, show_progress)\n",
        "    printDict = filterDict(self.trainerCV.best_state_dict, [\"epoch\", \"epoch_val_metrics\"])\n",
        "    # Save metrics calculated every epoch\n",
        "    if saveEpochMetrics: save_object(self.trainerCV.epochMetrics, os.path.join(CVPath, 'CVEpochMetrics.pkl'))\n",
        "    t1 = time()\n",
        "    print(f'Finished CV training with best metrics:\\n{printDict}')\n",
        "    if show_progress: print('\\n' + '='*100 + '\\n' + '='*100 + '\\n')\n",
        "    else: print(f'Time elapsed: {elapsedTime(t0, t1)}' + '\\n' + '='*100)\n",
        "    t0 = time()\n",
        "    # Train CS model\n",
        "    print('Training CS')\n",
        "    if show_progress: print('\\n')\n",
        "    CSPath = os.path.join(savePath, 'CSModel/')\n",
        "    cleanDir(CSPath)\n",
        "    self.CSTrain(epochs, CSPath, debug, scheduler, schedulerParams,\n",
        "            optimizerLR, saveBest, highestBest, print_CUDA, show_progress)\n",
        "    printDict = filterDict(self.trainerCS.best_state_dict, [\"epoch\", \"epoch_val_metrics\"])\n",
        "    # Save metrics calculated every epoch\n",
        "    if saveEpochMetrics: save_object(self.trainerCS.epochMetrics, os.path.join(CSPath, 'CSEpochMetrics.pkl'))\n",
        "    t1 = time()\n",
        "    print(f'Finished CS training with best metrics:\\n{printDict}')\n",
        "    if show_progress: print('\\n' + '='*100 + '\\n' + '='*100 + '\\n')\n",
        "    else: print(f'Time elapsed: {elapsedTime(t0, t1)}' + '\\n' + '='*100)\n",
        "    t0 = time()\n",
        "    # Train RV model\n",
        "    print('Training RV')\n",
        "    if show_progress: print('\\n')\n",
        "    RVPath = os.path.join(savePath, 'RVModel/')\n",
        "    cleanDir(RVPath)\n",
        "    self.RVTrain(epochs, RVPath, debug, scheduler, schedulerParams,\n",
        "            optimizerLR, saveBest, highestBest, print_CUDA, show_progress)\n",
        "    printDict = filterDict(self.trainerRV.best_state_dict, [\"epoch\", \"epoch_val_metrics\"])\n",
        "    # Save metrics calculated every epoch\n",
        "    if saveEpochMetrics: save_object(self.trainerRV.epochMetrics, os.path.join(RVPath, 'RVEpochMetrics.pkl'))\n",
        "    t1 = time()\n",
        "    print(f'Finished RV training with best metrics:\\n{printDict}')\n",
        "    if show_progress: print('\\n' + '='*100 + '\\n' + '='*100 + '\\n')\n",
        "    else: print(f'Time elapsed: {elapsedTime(t0, t1)}' + '\\n' + '='*100)\n",
        "    t0 = time()\n",
        "    # Train RS model\n",
        "    print('Training RS')\n",
        "    if show_progress: print('\\n')\n",
        "    RSPath = os.path.join(savePath, 'RSModel/')\n",
        "    cleanDir(RSPath)\n",
        "    self.RSTrain(epochs, RSPath, debug, scheduler, schedulerParams,\n",
        "            optimizerLR, saveBest, highestBest, print_CUDA, show_progress)\n",
        "    printDict = filterDict(self.trainerRS.best_state_dict, [\"epoch\", \"epoch_val_metrics\"])\n",
        "    # Save metrics calculated every epoch\n",
        "    if saveEpochMetrics: save_object(self.trainerRS.epochMetrics, os.path.join(RSPath, 'RSEpochMetrics.pkl'))\n",
        "    t1 = time()\n",
        "    print(f'Finished RS training with best metrics:\\n{printDict}')\n",
        "    if show_progress: print('\\n' + '='*100 + '\\n' + '='*100 + '\\n' + 'Finished training!')\n",
        "    else: print(f'Time elapsed: {elapsedTime(t0, t1)}' + '\\n' + '='*100)\n",
        "\n",
        "  def load_trainedData(self, epochMetricsDict, bestStatesDict):\n",
        "    '''\n",
        "    Load metrics and trained model parameters\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    epochMetricsDict: dict\n",
        "      Dictionary with metrics for every epoch\n",
        "    bestStatedDict: dict\n",
        "      Models' state dictionaries on the best epoch\n",
        "    '''\n",
        "    self.trainerCV = PytorchTrainer()\n",
        "    self.trainerCS = PytorchTrainer()\n",
        "    self.trainerRV = PytorchTrainer()\n",
        "    self.trainerRS = PytorchTrainer()\n",
        "    self.trainerCV.epochMetrics = load_object(epochMetricsDict['CV'])\n",
        "    self.trainerCS.epochMetrics = load_object(epochMetricsDict['CS'])\n",
        "    self.trainerRV.epochMetrics = load_object(epochMetricsDict['RV'])\n",
        "    self.trainerRS.epochMetrics = load_object(epochMetricsDict['RS'])\n",
        "    self.trainerCV.best_state_dict = torch.load(bestStatesDict['CV'])\n",
        "    self.trainerCS.best_state_dict = torch.load(bestStatesDict['CS'])\n",
        "    self.trainerRV.best_state_dict = torch.load(bestStatesDict['RV'])\n",
        "    self.trainerRS.best_state_dict = torch.load(bestStatesDict['RS'])\n",
        "\n",
        "  def testModel(self, state_dicts, device, debug = False):\n",
        "    '''\n",
        "    Test trained models\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    state_dicts: dict\n",
        "      Models' state dictionaries\n",
        "    device: str\n",
        "      Device to test the models on. Either 'cuda' or 'cpu'\n",
        "    debug: bool, optional\n",
        "      If True, show debugging of models' layers output shapes. Default: False\n",
        "    '''\n",
        "    for modelName, model in {'CV': self.modelCV, 'CS': self.modelCS, 'RV': self.modelRV, 'RS': self.modelRS}.items():\n",
        "      try:\n",
        "        model.load_state_dict(state_dicts[modelName])\n",
        "      except:\n",
        "        print(f'{modelName} doesn\\'t exist!\\n')\n",
        "      model.to(device)\n",
        "      # state_dicts = {m: {k: v.to(device) for k, v in sd.items()} for m, sd in state_dicts.items()}\n",
        "      model.eval()\n",
        "      allOutputs = torch.tensor([]).detach().to('cpu')\n",
        "      allLabels = torch.tensor([]).detach().to('cpu')\n",
        "      for inputs, labels in self.test_dl:\n",
        "        seq_len = inputs.size(1)\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs, debug = debug)\n",
        "        outputs = outputProcessing(outputs = outputs, seq_len = seq_len, clf = model.clf, framePred = model.framePred)\n",
        "        if debug: print(f'Outputs processing size: {outputs.size()}')\n",
        "        outputs = outputs.detach().to('cpu')\n",
        "        allOutputs = torch.cat([allOutputs, outputs], dim = 0).detach().to('cpu')\n",
        "        allLabels = torch.cat([allLabels, labels], dim = 0).detach().to('cpu')\n",
        "        del inputs\n",
        "        del labels\n",
        "        del outputs\n",
        "        torch.cuda.empty_cache()\n",
        "      for name, metric in self.metrics.items():\n",
        "        value = metric(allOutputs, allLabels).detach().to('cpu')\n",
        "        print(f'{modelName} test {name}: {value.item():.4f}')\n",
        "        del value\n",
        "      print('='*50)\n",
        "    \n",
        "  def plot_metrics(self, types, colors, mapper = False, plot_train = True, plot_val = True, **kwargs):\n",
        "    if not mapper:\n",
        "      try:\n",
        "        mapper = {'CV': self.trainerCV.epochMetrics, 'CS': self.trainerCS.epochMetrics, \n",
        "                  'RV': self.trainerRV.epochMetrics, 'RS': self.trainerRS.epochMetrics}\n",
        "      except:\n",
        "        raise ValueError(f'Not all training setups in types have been trained yet!')\n",
        "    listMetrics = [mapper[i] for i in types]\n",
        "    plot_epoch_metrics(listEpochMetrics = listMetrics, metrics = self.metrics,\n",
        "                       prefixs = types, colors = colors, plot_train = plot_train,\n",
        "                       plot_val = plot_val, **kwargs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HydayLXEaXAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KFold Setup"
      ],
      "metadata": {
        "id": "tqIugKwJGN-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KFoldSetup(TrainingSetup):\n",
        "  '''Setup KFold cross-validation training'''\n",
        "  def __init__(self, n_splits, modelVidParams, modelSmplParams, dataParams, metrics, device, shuffle = True,\n",
        "               start_fold = 0, end_fold = 10):\n",
        "    '''\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    modelVidParams: dict\n",
        "      Parameters of the Transformer model for video prediction (CV and RV).\n",
        "    modelSmplParams: dict\n",
        "      Parameters of the Transformer model for sample prediction (CS and RS).\n",
        "    dataParams: dict\n",
        "      Parameters for dataloaders creation\n",
        "    metrics: dict\n",
        "      Dictionary {metric: metric class} for metrics used in evaluation\n",
        "    device: str\n",
        "      Device to train the model on. Either 'cuda' or 'cpu'\n",
        "    shuffle: bool, optional\n",
        "      If True (default), shuffle data when creating folds\n",
        "    start_fold: int\n",
        "      First fold to train (for training models on multiple devices concurrently)\n",
        "    end_fold: int\n",
        "      Last fold to train (for training models on multiple devices concurrently)\n",
        "    '''\n",
        "    # For KFold training, eliminating test data split, keeping only train and validation\n",
        "    if dataParams['test_size'] != 0: \n",
        "      print('test_size should be 0 for KFold. Setting test_size to 0...')\n",
        "      dataParams['test_size'] = 0\n",
        "    super().__init__(modelVidParams, modelSmplParams, dataParams, metrics, device)\n",
        "    self.n_splits = n_splits\n",
        "    self.shuffle = shuffle\n",
        "    self.loaders_created = False\n",
        "    self.start_fold = start_fold\n",
        "    self.end_fold = end_fold\n",
        "\n",
        "  def generate_kfold_loaders(self, X, y, splitsPath, sampling_rate = 1, kfold_splits = None):\n",
        "    '''\n",
        "    Create data loaders for each fold\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    X: torch.Tensor\n",
        "      Features tensor\n",
        "    y: torch.Tensor\n",
        "      Labels tensor\n",
        "    splitsPath: str\n",
        "      Path to save KFold splits' indexes\n",
        "    sampling_rate: int, optional\n",
        "      Rate for downsampling (e.g. for sample_rate=30, only one sample is retained every 30 samples). Default: 1\n",
        "    kfold_splits: list\n",
        "      List of pre-determined indexes for each KFold split. If None, generate KFold splits.\n",
        "    '''\n",
        "    # Generate KFold splits\n",
        "    train_size, val_size = [self.dataParams['train_size'], self.dataParams['val_size']]\n",
        "    if not self.dataParams['allData']:\n",
        "      idxs = np.random.randint(len(X), size = train_size + val_size)\n",
        "      Xset, yset = X[idxs], y[idxs]\n",
        "    else: Xset, yset = copy(X), copy(y)\n",
        "    if not kfold_splits:\n",
        "      kf = KFold(n_splits = self.n_splits, shuffle = self.shuffle)\n",
        "      kf.get_n_splits(Xset)\n",
        "      kfold_splits = [i for i in kf.split(Xset)]\n",
        "      save_object(kfold_splits, os.path.join(splitsPath, 'kfold_splits.pkl'))\n",
        "    self.kfold_loaders = []\n",
        "    self.kfold_splits = kfold_splits\n",
        "    # For each split, create train and validation data loaders\n",
        "    for train_index, val_index in kfold_splits[self.start_fold:self.end_fold]:\n",
        "      random.shuffle(train_index)\n",
        "      random.shuffle(val_index)\n",
        "      if self.dataParams['transform']:\n",
        "        (Xt, yt), (Xv, yv) = [applyTransform(X = i, y = j, transform = self.dataParams['transform'])\n",
        "                              for i, j in [(Xset[train_index], yset[train_index]), (Xset[val_index], yset[val_index])]]\n",
        "      else: \n",
        "        (Xt, yt), (Xv, yv) = [(torch.Tensor(i), torch.Tensor(j)) \n",
        "                              for i, j in [(Xset[train_index], yset[train_index]), (Xset[val_index], yset[val_index])]]\n",
        "      train_val_test_data = [Xt, Xv, yt, yv]\n",
        "      self.getData(X, y, train_val_test_data, sampling_rate, plot = False, figsize = None)\n",
        "      self.dataParams['debug'] = False\n",
        "      self.kfold_loaders.append((self.train_dl, self.val_dl))\n",
        "    self.loaders_created = True\n",
        "\n",
        "  def kfold_train(self, epochs, savePath, debug = False, scheduler = None, schedulerParams = None,\n",
        "                  optimizerLR = 1e-3, saveBest = 'PCC', highestBest = True, print_CUDA = False,\n",
        "                  saveEpochMetrics = False, fold_metrics = None, train = True):\n",
        "    '''\n",
        "    Train models using KFold cross-validation\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------------------\n",
        "    epochs: int\n",
        "      Number of epochs\n",
        "    savePath: str\n",
        "      Path to save results of training and validation\n",
        "    debug: bool, optional\n",
        "      If True (default), show debugging of models' layers output shapes\n",
        "    scheduler: torch.optim class, optional\n",
        "      Learning rate scheduler (e.g. torch.optim.StepLR)\n",
        "    schedulerParams: dict, optional\n",
        "      Parameters of the scheduler\n",
        "    optimizerLR: float\n",
        "      Initial learning rate of the optimizer\n",
        "    saveBest: str, optional\n",
        "      Metric to consider when evaluating best model. Either 'PCC' (default), 'SCC' or 'RMSE'.\n",
        "    highestBest: bool, optional\n",
        "      If True (default), model is considered best if metric (defined in saveBest) is the highest. If False, if its the lowest.\n",
        "    print_CUDA: bool, optional\n",
        "      If True, print CUDA memory usage at the end of the epoch. Default: False\n",
        "    saveEpochMetrics: bool, optional\n",
        "      If True (default), save metrics calculated every epoch to a pickle file (with path defined on savePath)\n",
        "    fold_metrics: list, optional\n",
        "      List of previously trained metrics dictionaries for each fold\n",
        "    train: bool, optional\n",
        "      If True (default), train the model. If False, only load metrics\n",
        "    '''\n",
        "    if not self.loaders_created:\n",
        "      raise ValueError('KFold dataloaders were not created yet')\n",
        "    self.fold_metrics = fold_metrics if fold_metrics is not None else []\n",
        "    if train:\n",
        "      for idx, (train_dl, val_dl) in enumerate(self.kfold_loaders):\n",
        "        print('*'*200)\n",
        "        print(f'Training fold {self.start_fold+idx+1}...')\n",
        "        print('*'*200 + '\\n')\n",
        "        t0fold = time()\n",
        "        svPth = os.path.join(savePath, f'fold{self.start_fold+idx+1}')\n",
        "        if not os.path.isdir(svPth): os.mkdir(svPth)\n",
        "        self.train(epochs, svPth, debug, scheduler, schedulerParams, optimizerLR, saveBest, \n",
        "                  highestBest, print_CUDA, saveEpochMetrics, show_progress = False)\n",
        "        t1fold = time()\n",
        "        print(f'Total time elapsed on fold {self.start_fold+idx+1}: {elapsedTime(t0fold, t1fold)}\\n')\n",
        "        bestMetrics = {\n",
        "          'CV': self.trainerCV.best_state_dict['epoch_val_metrics'],\n",
        "          'CS': self.trainerCS.best_state_dict['epoch_val_metrics'],\n",
        "          'RV': self.trainerRV.best_state_dict['epoch_val_metrics'],\n",
        "          'RS': self.trainerRS.best_state_dict['epoch_val_metrics'],\n",
        "        }\n",
        "        self.fold_metrics.append(bestMetrics)\n",
        "        save_object(bestMetrics, os.path.join(svPth, f'fold{self.start_fold+idx+1}_bestMetrics.pkl'))\n",
        "        save_object(self.fold_metrics, os.path.join(savePath, f'kfold_{self.start_fold+1}-{self.end_fold}-_bestMetrics.pkl'))\n",
        "        self.createModels()\n",
        "      print('*'*100)\n",
        "      print(f'Finished training KFold Cross Validation!')\n",
        "      print('*'*100)\n",
        "      save_object(self.fold_metrics, os.path.join(svPth, f'kfold_{start_fold+1}-{end_fold}_bestMetrics.pkl'))\n",
        "      "
      ],
      "metadata": {
        "id": "tL5hA_2jGQeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train using audiovisual features"
      ],
      "metadata": {
        "id": "AAmrWciJ2SL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_fold = 0\n",
        "end_fold = 9"
      ],
      "metadata": {
        "id": "Hd2JJEzpE7BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Original data"
      ],
      "metadata": {
        "id": "FvZD27-H8_lf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Params and data"
      ],
      "metadata": {
        "id": "HfGjPiAGYAwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelVidParams = {\n",
        "'emb_dim': 8,\n",
        "'seq_len': 1187,\n",
        "'num_features': 115,\n",
        "'nhead': 4,\n",
        "'d_hid': 32,\n",
        "'nlayers': 4,\n",
        "'emb_activ': nn.GELU,\n",
        "'linear_activ': nn.GELU,\n",
        "'dropout': 0.1,\n",
        "'batch_first': True\n",
        "}\n",
        "\n",
        "modelSmplParams = {\n",
        "'emb_dim': 4,\n",
        "'seq_len': 1187,\n",
        "'num_features': 115,\n",
        "'nhead': 4,\n",
        "'d_hid': 32,\n",
        "'nlayers': 2,\n",
        "'emb_activ': nn.GELU,\n",
        "'linear_activ': nn.GELU,\n",
        "'dropout': 0.1,\n",
        "'batch_first': True\n",
        "}\n",
        "\n",
        "dataParams = {\n",
        "'mosPath': '/content/drive/MyDrive/TCC Dados/Experiment_3/UnB-AVQ-2018-Experiment3.csv',\n",
        "'matPath': '/content/drive/MyDrive/TCC Dados/Experiment_3/Features',\n",
        "'featuresName': 'avFeatures',\n",
        "'read_data': False,\n",
        "'batch_size': 4,\n",
        "'bs_smpl': 2,\n",
        "'train_size': 720,\n",
        "'val_size': 80,\n",
        "'test_size': 0,\n",
        "'allData': False,\n",
        "'transform': MinMaxScaler,\n",
        "'debug': True,\n",
        "'shuffle': True,\n",
        "'idxs': None\n",
        "}\n",
        "metrics = {'RMSE': RMSE(), 'PCC': PearsonCorrelation(), 'SCC': SpearmanCorrelation()}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_splits = 10\n",
        "shuffle = True\n",
        "\n",
        "splitsPath = '/content/drive/MyDrive/TCC Resultados/AVQ_KFold_1-2'\n",
        "if not os.path.isdir(splitsPath): os.mkdir(splitsPath)\n",
        "sampling_rate = 1\n",
        "kfold_splits = load_object('/content/drive/MyDrive/TCC Dados/kfold_splits.pkl')"
      ],
      "metadata": {
        "id": "jWKtkMcbIzH2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "b5e32507-4010-4221-a7d9-ad054f6d9b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f740828be05f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m'd_hid'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m'nlayers'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;34m'emb_activ'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGELU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m'linear_activ'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGELU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m'dropout'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kfsetup = KFoldSetup(n_splits, modelVidParams, modelSmplParams, dataParams, metrics, device, shuffle,\n",
        "                     start_fold, end_fold)\n",
        "kfsetup.generate_kfold_loaders(X, y, splitsPath, sampling_rate, kfold_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykMHBKaBIiIe",
        "outputId": "f017b9c3-8c4e-446a-fffb-1c0ed8c4cd1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data...\n",
            "Train/val data shapes:\n",
            "torch.Size([720, 1187, 115]), torch.Size([80, 1187, 115])\n",
            "torch.Size([720]), torch.Size([80])\n",
            "\n",
            "Creating dataloaders...\n",
            "Dataloaders created!\n",
            "Dataloaders sizes:\n",
            "180, 20\n",
            "Preparing data...\n",
            "Train/val data shapes:\n",
            "torch.Size([720, 1187, 115]), torch.Size([80, 1187, 115])\n",
            "torch.Size([720]), torch.Size([80])\n",
            "\n",
            "Creating dataloaders...\n",
            "Dataloaders created!\n",
            "Dataloaders sizes:\n",
            "360, 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "Bp6CFBlvYDOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "saveBest = 'PCC'\n",
        "highestBest = True\n",
        "debug = False\n",
        "scheduler = True\n",
        "print_CUDA = False\n",
        "saveEpochMetrics = False\n",
        "fold_metrics = None\n",
        "# fold_metrics = load_object('/content/drive/MyDrive/TCC Dados/KFold/kfold_bestMetrics.pkl')\n",
        "train = True"
      ],
      "metadata": {
        "id": "5WVoe5uJqZ4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "savePath = '/content/drive/MyDrive/TCC Resultados/AVQ_KFold_1-2'\n",
        "if not os.path.isdir(savePath):\n",
        "  os.mkdir(savePath)\n",
        "kfsetup.kfold_train(epochs, savePath, debug = debug, scheduler = scheduler,\n",
        "                    saveBest = saveBest, highestBest = highestBest, print_CUDA = print_CUDA,\n",
        "                    saveEpochMetrics = saveEpochMetrics, fold_metrics = fold_metrics, train = train)"
      ],
      "metadata": {
        "id": "qxtkqP5HIiZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b78ca8-7d07-4d75-a604-2acbc641d111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************************************************************************************************************************************************************************************\n",
            "Training fold 1...\n",
            "********************************************************************************************************************************************************************************************************\n",
            "\n",
            "Training CV\n",
            "Time for 1st epoch: 0m11s\n",
            "Estimated time for 10 epochs: 1m50s\n",
            "Finished CV training with best metrics:\n",
            "{'epoch': 10, 'epoch_val_metrics': {'RMSE': 1.0493, 'PCC': 0.1261, 'SCC': 0.0341}}\n",
            "Time elapsed: 1m32s\n",
            "====================================================================================================\n",
            "Training CS\n",
            "Time for 1st epoch: 0m47s\n",
            "Estimated time for 10 epochs: 7m59s\n",
            "Finished CS training with best metrics:\n",
            "{'epoch': 3, 'epoch_val_metrics': {'RMSE': 1.6776, 'PCC': -0.0481, 'SCC': 0.0086}}\n",
            "Time elapsed: 8m5s\n",
            "====================================================================================================\n",
            "Training RV\n",
            "Time for 1st epoch: 0m8s\n",
            "Estimated time for 10 epochs: 1m25s\n",
            "Finished RV training with best metrics:\n",
            "{'epoch': 9, 'epoch_val_metrics': {'RMSE': 0.9652, 'PCC': 0.1169, 'SCC': 0.1402}}\n",
            "Time elapsed: 1m26s\n",
            "====================================================================================================\n",
            "Training RS\n",
            "Time for 1st epoch: 0m48s\n",
            "Estimated time for 10 epochs: 8m3s\n",
            "Finished RS training with best metrics:\n",
            "{'epoch': 8, 'epoch_val_metrics': {'RMSE': 0.9692, 'PCC': 0.2178, 'SCC': 0.2717}}\n",
            "Time elapsed: 8m0s\n",
            "====================================================================================================\n",
            "Total time elapsed on fold 1: 19m5s\n",
            "\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Training fold 2...\n",
            "********************************************************************************************************************************************************************************************************\n",
            "\n",
            "Training CV\n",
            "Time for 1st epoch: 0m8s\n",
            "Estimated time for 10 epochs: 1m25s\n",
            "Finished CV training with best metrics:\n",
            "{'epoch': 10, 'epoch_val_metrics': {'RMSE': 1.0498, 'PCC': 0.3343, 'SCC': 0.2086}}\n",
            "Time elapsed: 1m26s\n",
            "====================================================================================================\n",
            "Training CS\n",
            "Time for 1st epoch: 0m48s\n",
            "Estimated time for 10 epochs: 8m8s\n",
            "Finished CS training with best metrics:\n",
            "{'epoch': 5, 'epoch_val_metrics': {'RMSE': 1.6814, 'PCC': 0.1227, 'SCC': 0.1948}}\n",
            "Time elapsed: 8m6s\n",
            "====================================================================================================\n",
            "Training RV\n",
            "Time for 1st epoch: 0m8s\n",
            "Estimated time for 10 epochs: 1m24s\n",
            "Finished RV training with best metrics:\n",
            "{'epoch': 7, 'epoch_val_metrics': {'RMSE': 0.9458, 'PCC': 0.298, 'SCC': 0.0992}}\n",
            "Time elapsed: 1m26s\n",
            "====================================================================================================\n",
            "Training RS\n",
            "Time for 1st epoch: 0m48s\n",
            "Estimated time for 10 epochs: 8m3s\n",
            "Finished RS training with best metrics:\n",
            "{'epoch': 7, 'epoch_val_metrics': {'RMSE': 0.9768, 'PCC': 0.1009, 'SCC': 0.0991}}\n",
            "Time elapsed: 8m1s\n",
            "====================================================================================================\n",
            "Total time elapsed on fold 2: 19m1s\n",
            "\n",
            "****************************************************************************************************\n",
            "Finished training KFold Cross Validation!\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downsampled data"
      ],
      "metadata": {
        "id": "0gm6lyRWAJ34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Params and data"
      ],
      "metadata": {
        "id": "u9Su3GYgAJ39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del kfsetup\n",
        "\n",
        "modelVidParams = {\n",
        "'emb_dim': 8,\n",
        "'seq_len': 40,\n",
        "'num_features': 115,\n",
        "'nhead': 4,\n",
        "'d_hid': 32,\n",
        "'nlayers': 4,\n",
        "'emb_activ': nn.GELU,\n",
        "'linear_activ': nn.GELU,\n",
        "'dropout': 0.1,\n",
        "'batch_first': True\n",
        "}\n",
        "\n",
        "modelSmplParams = {\n",
        "'emb_dim': 4,\n",
        "'seq_len': 40,\n",
        "'num_features': 115,\n",
        "'nhead': 4,\n",
        "'d_hid': 32,\n",
        "'nlayers': 2,\n",
        "'emb_activ': nn.GELU,\n",
        "'linear_activ': nn.GELU,\n",
        "'dropout': 0.1,\n",
        "'batch_first': True\n",
        "}\n",
        "\n",
        "splitsPath = '/content/drive/MyDrive/TCC Resultados/AVQ_Sample_KFold_1-2'\n",
        "if not os.path.isdir(splitsPath): os.mkdir(splitsPath)\n",
        "sampling_rate = 30"
      ],
      "metadata": {
        "id": "gM3Pqx09AJ39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataParams['debug'] = True\n",
        "kfsetup_smpl = KFoldSetup(n_splits, modelVidParams, modelSmplParams, dataParams, metrics, device, shuffle,\n",
        "                     start_fold, end_fold)\n",
        "kfsetup_smpl.generate_kfold_loaders(X, y, splitsPath, sampling_rate, kfold_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce81dd1c-e8a0-4220-a7e7-8b15ae8c66e1",
        "id": "IahfHWWwAJ3-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data...\n",
            "Train/val data shapes:\n",
            "torch.Size([720, 40, 115]), torch.Size([80, 40, 115])\n",
            "torch.Size([720]), torch.Size([80])\n",
            "\n",
            "Creating dataloaders...\n",
            "Dataloaders created!\n",
            "Dataloaders sizes:\n",
            "180, 20\n",
            "Preparing data...\n",
            "Train/val data shapes:\n",
            "torch.Size([720, 40, 115]), torch.Size([80, 40, 115])\n",
            "torch.Size([720]), torch.Size([80])\n",
            "\n",
            "Creating dataloaders...\n",
            "Dataloaders created!\n",
            "Dataloaders sizes:\n",
            "360, 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "putgxh04AJ3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "saveBest = 'PCC'\n",
        "highestBest = True\n",
        "debug = False\n",
        "scheduler = True\n",
        "print_CUDA = False\n",
        "saveEpochMetrics = False\n",
        "fold_metrics = None\n",
        "# fold_metrics = load_object('/content/drive/MyDrive/TCC Dados/KFold/kfold_bestMetrics.pkl')\n",
        "train = True"
      ],
      "metadata": {
        "id": "o2lih3a6AJ3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "savePath = '/content/drive/MyDrive/TCC Resultados/AVQ_Sample_KFold_1-2'\n",
        "if not os.path.isdir(savePath):\n",
        "  os.mkdir(savePath)\n",
        "kfsetup_smpl.kfold_train(epochs, savePath, debug = debug, scheduler = scheduler,\n",
        "                    saveBest = saveBest, highestBest = highestBest, print_CUDA = print_CUDA,\n",
        "                    saveEpochMetrics = saveEpochMetrics, fold_metrics = fold_metrics, train = train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b236b6-2de9-4fa7-fb77-fe4f77e975b1",
        "id": "pCNaKJOwAJ3-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************************************************************************************************************************************************************************************\n",
            "Training fold 1...\n",
            "********************************************************************************************************************************************************************************************************\n",
            "\n",
            "Training CV\n",
            "Time for 1st epoch: 0m2s\n",
            "Estimated time for 10 epochs: 0m23s\n",
            "Finished CV training with best metrics:\n",
            "{'epoch': 7, 'epoch_val_metrics': {'RMSE': 1.0085, 'PCC': 0.1405, 'SCC': 0.1113}}\n",
            "Time elapsed: 0m24s\n",
            "====================================================================================================\n",
            "Training CS\n",
            "Time for 1st epoch: 0m3s\n",
            "Estimated time for 10 epochs: 0m32s\n",
            "Finished CS training with best metrics:\n",
            "{'epoch': 8, 'epoch_val_metrics': {'RMSE': 1.5907, 'PCC': 0.1498, 'SCC': 0.2646}}\n",
            "Time elapsed: 0m31s\n",
            "====================================================================================================\n",
            "Training RV\n",
            "Time for 1st epoch: 0m2s\n",
            "Estimated time for 10 epochs: 0m24s\n",
            "Finished RV training with best metrics:\n",
            "{'epoch': 1, 'epoch_val_metrics': {'RMSE': 1.6435, 'PCC': 0.0627, 'SCC': 0.0834}}\n",
            "Time elapsed: 0m23s\n",
            "====================================================================================================\n",
            "Training RS\n",
            "Time for 1st epoch: 0m3s\n",
            "Estimated time for 10 epochs: 0m31s\n",
            "Finished RS training with best metrics:\n",
            "{'epoch': 8, 'epoch_val_metrics': {'RMSE': 1.0054, 'PCC': 0.2401, 'SCC': 0.1643}}\n",
            "Time elapsed: 0m30s\n",
            "====================================================================================================\n",
            "Total time elapsed on fold 1: 1m49s\n",
            "\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Training fold 2...\n",
            "********************************************************************************************************************************************************************************************************\n",
            "\n",
            "Training CV\n",
            "Time for 1st epoch: 0m2s\n",
            "Estimated time for 10 epochs: 0m23s\n",
            "Finished CV training with best metrics:\n",
            "{'epoch': 3, 'epoch_val_metrics': {'RMSE': 1.0175, 'PCC': 0.0737, 'SCC': 0.1008}}\n",
            "Time elapsed: 0m23s\n",
            "====================================================================================================\n",
            "Training CS\n",
            "Time for 1st epoch: 0m3s\n",
            "Estimated time for 10 epochs: 0m38s\n",
            "Finished CS training with best metrics:\n",
            "{'epoch': 10, 'epoch_val_metrics': {'RMSE': 1.5877, 'PCC': 0.1899, 'SCC': 0.1188}}\n",
            "Time elapsed: 0m33s\n",
            "====================================================================================================\n",
            "Training RV\n",
            "Time for 1st epoch: 0m2s\n",
            "Estimated time for 10 epochs: 0m23s\n",
            "Finished RV training with best metrics:\n",
            "{'epoch': 3, 'epoch_val_metrics': {'RMSE': 0.9827, 'PCC': 0.0508, 'SCC': 0.016}}\n",
            "Time elapsed: 0m23s\n",
            "====================================================================================================\n",
            "Training RS\n",
            "Time for 1st epoch: 0m3s\n",
            "Estimated time for 10 epochs: 0m31s\n",
            "Finished RS training with best metrics:\n",
            "{'epoch': 4, 'epoch_val_metrics': {'RMSE': 1.0064, 'PCC': 0.0203, 'SCC': -0.0165}}\n",
            "Time elapsed: 0m30s\n",
            "====================================================================================================\n",
            "Total time elapsed on fold 2: 1m51s\n",
            "\n",
            "****************************************************************************************************\n",
            "Finished training KFold Cross Validation!\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train using only audio features"
      ],
      "metadata": {
        "id": "78ReAKS1Bvlc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Original data"
      ],
      "metadata": {
        "id": "ey4myPOEBvlh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Params and data"
      ],
      "metadata": {
        "id": "Al-acU8FBvlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del kfsetup_smpl\n",
        "\n",
        "modelVidParams = {\n",
        "'emb_dim': 8,\n",
        "'seq_len': 1187,\n",
        "'num_features': 25,\n",
        "'nhead': 4,\n",
        "'d_hid': 32,\n",
        "'nlayers': 4,\n",
        "'emb_activ': nn.GELU,\n",
        "'linear_activ': nn.GELU,\n",
        "'dropout': 0.1,\n",
        "'batch_first': True\n",
        "}\n",
        "\n",
        "modelSmplParams = {\n",
        "'emb_dim': 4,\n",
        "'seq_len': 1187,\n",
        "'num_features': 25,\n",
        "'nhead': 4,\n",
        "'d_hid': 32,\n",
        "'nlayers': 2,\n",
        "'emb_activ': nn.GELU,\n",
        "'linear_activ': nn.GELU,\n",
        "'dropout': 0.1,\n",
        "'batch_first': True\n",
        "}\n",
        "\n",
        "splitsPath = '/content/drive/MyDrive/TCC Resultados/AQ_KFold_1-2'\n",
        "if not os.path.isdir(splitsPath): os.mkdir(splitsPath)\n",
        "sampling_rate = 1"
      ],
      "metadata": {
        "id": "RBjMl15hBvlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataParams['debug'] = True\n",
        "kfsetup_AQ = KFoldSetup(n_splits, modelVidParams, modelSmplParams, dataParams, metrics, device, shuffle,\n",
        "                     start_fold, end_fold)\n",
        "kfsetup_AQ.generate_kfold_loaders(X[:, :, 90:], y, splitsPath, sampling_rate, kfold_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7830f0f-1c0c-4a94-8e62-f474d8776c7b",
        "id": "gm7WuDf8Bvlh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data...\n",
            "Train/val data shapes:\n",
            "torch.Size([720, 1187, 25]), torch.Size([80, 1187, 25])\n",
            "torch.Size([720]), torch.Size([80])\n",
            "\n",
            "Creating dataloaders...\n",
            "Dataloaders created!\n",
            "Dataloaders sizes:\n",
            "180, 20\n",
            "Preparing data...\n",
            "Train/val data shapes:\n",
            "torch.Size([720, 1187, 25]), torch.Size([80, 1187, 25])\n",
            "torch.Size([720]), torch.Size([80])\n",
            "\n",
            "Creating dataloaders...\n",
            "Dataloaders created!\n",
            "Dataloaders sizes:\n",
            "360, 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "0CBTHb8YBvli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "savePath = '/content/drive/MyDrive/TCC Resultados/AQ_KFold_1-2'\n",
        "if not os.path.isdir(savePath):\n",
        "  os.mkdir(savePath)\n",
        "kfsetup_AQ.kfold_train(epochs, savePath, debug = debug, scheduler = scheduler,\n",
        "                    saveBest = saveBest, highestBest = highestBest, print_CUDA = print_CUDA,\n",
        "                    saveEpochMetrics = saveEpochMetrics, fold_metrics = fold_metrics, train = train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d62246-3ef3-45d0-8672-170ed1cd088f",
        "id": "ivYDYAWsBvli"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************************************************************************************************************************************************************************************\n",
            "Training fold 1...\n",
            "********************************************************************************************************************************************************************************************************\n",
            "\n",
            "Training CV\n",
            "Time for 1st epoch: 0m8s\n",
            "Estimated time for 10 epochs: 1m22s\n",
            "Finished CV training with best metrics:\n",
            "{'epoch': 6, 'epoch_val_metrics': {'RMSE': 1.3083, 'PCC': 0.2894, 'SCC': 0.3546}}\n",
            "Time elapsed: 1m23s\n",
            "====================================================================================================\n",
            "Training CS\n",
            "Time for 1st epoch: 0m5s\n",
            "Estimated time for 10 epochs: 0m59s\n",
            "Finished CS training with best metrics:\n",
            "{'epoch': 6, 'epoch_val_metrics': {'RMSE': 1.9652, 'PCC': 0.1992, 'SCC': 0.1091}}\n",
            "Time elapsed: 0m58s\n",
            "====================================================================================================\n",
            "Training RV\n",
            "Time for 1st epoch: 0m8s\n",
            "Estimated time for 10 epochs: 1m21s\n",
            "Finished RV training with best metrics:\n",
            "{'epoch': 10, 'epoch_val_metrics': {'RMSE': 1.1247, 'PCC': 0.2478, 'SCC': 0.1218}}\n",
            "Time elapsed: 1m22s\n",
            "====================================================================================================\n",
            "Training RS\n",
            "Time for 1st epoch: 0m5s\n",
            "Estimated time for 10 epochs: 0m58s\n",
            "Finished RS training with best metrics:\n",
            "{'epoch': 10, 'epoch_val_metrics': {'RMSE': 1.1616, 'PCC': 0.2166, 'SCC': 0.0252}}\n",
            "Time elapsed: 0m56s\n",
            "====================================================================================================\n",
            "Total time elapsed on fold 1: 4m41s\n",
            "\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Training fold 2...\n",
            "********************************************************************************************************************************************************************************************************\n",
            "\n",
            "Training CV\n",
            "Time for 1st epoch: 0m8s\n",
            "Estimated time for 10 epochs: 1m21s\n",
            "Finished CV training with best metrics:\n",
            "{'epoch': 6, 'epoch_val_metrics': {'RMSE': 1.3088, 'PCC': 0.2881, 'SCC': 0.3534}}\n",
            "Time elapsed: 1m23s\n",
            "====================================================================================================\n",
            "Training CS\n",
            "Time for 1st epoch: 0m5s\n",
            "Estimated time for 10 epochs: 0m59s\n",
            "Finished CS training with best metrics:\n",
            "{'epoch': 1, 'epoch_val_metrics': {'RMSE': 1.9836, 'PCC': 0.1438, 'SCC': 0.038}}\n",
            "Time elapsed: 0m58s\n",
            "====================================================================================================\n",
            "Training RV\n",
            "Time for 1st epoch: 0m8s\n",
            "Estimated time for 10 epochs: 1m20s\n",
            "Finished RV training with best metrics:\n",
            "{'epoch': 9, 'epoch_val_metrics': {'RMSE': 1.1477, 'PCC': 0.2113, 'SCC': 0.1343}}\n",
            "Time elapsed: 1m22s\n",
            "====================================================================================================\n",
            "Training RS\n",
            "Time for 1st epoch: 0m5s\n",
            "Estimated time for 10 epochs: 0m58s\n",
            "Finished RS training with best metrics:\n",
            "{'epoch': 7, 'epoch_val_metrics': {'RMSE': 1.1552, 'PCC': 0.2326, 'SCC': 0.0657}}\n",
            "Time elapsed: 0m56s\n",
            "====================================================================================================\n",
            "Total time elapsed on fold 2: 4m40s\n",
            "\n",
            "****************************************************************************************************\n",
            "Finished training KFold Cross Validation!\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downsampled data"
      ],
      "metadata": {
        "id": "yD67LXylBvli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Params and data"
      ],
      "metadata": {
        "id": "q9jl7qBjBvli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del kfsetup_AQ\n",
        "\n",
        "modelVidParams = {\n",
        "'emb_dim': 8,\n",
        "'seq_len': 40,\n",
        "'num_features': 25,\n",
        "'nhead': 4,\n",
        "'d_hid': 32,\n",
        "'nlayers': 4,\n",
        "'emb_activ': nn.GELU,\n",
        "'linear_activ': nn.GELU,\n",
        "'dropout': 0.1,\n",
        "'batch_first': True\n",
        "}\n",
        "\n",
        "modelSmplParams = {\n",
        "'emb_dim': 4,\n",
        "'seq_len': 40,\n",
        "'num_features': 25,\n",
        "'nhead': 4,\n",
        "'d_hid': 32,\n",
        "'nlayers': 2,\n",
        "'emb_activ': nn.GELU,\n",
        "'linear_activ': nn.GELU,\n",
        "'dropout': 0.1,\n",
        "'batch_first': True\n",
        "}\n",
        "\n",
        "splitsPath = '/content/drive/MyDrive/TCC Resultados/AQ_Sample_KFold_1-2'\n",
        "if not os.path.isdir(splitsPath): os.mkdir(splitsPath)\n",
        "sampling_rate = 30"
      ],
      "metadata": {
        "id": "HRxkAoVlBvli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataParams['debug'] = True\n",
        "kfsetup_AQ_smpl = KFoldSetup(n_splits, modelVidParams, modelSmplParams, dataParams, metrics, device, shuffle,\n",
        "                     start_fold, end_fold)\n",
        "kfsetup_AQ_smpl.generate_kfold_loaders(X[:, :, 90:], y, splitsPath, sampling_rate, kfold_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a745e8bc-5bbd-4fe3-f154-865a6af64040",
        "id": "B2Mb2FYgBvli"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data...\n",
            "Train/val data shapes:\n",
            "torch.Size([720, 40, 25]), torch.Size([80, 40, 25])\n",
            "torch.Size([720]), torch.Size([80])\n",
            "\n",
            "Creating dataloaders...\n",
            "Dataloaders created!\n",
            "Dataloaders sizes:\n",
            "180, 20\n",
            "Preparing data...\n",
            "Train/val data shapes:\n",
            "torch.Size([720, 40, 25]), torch.Size([80, 40, 25])\n",
            "torch.Size([720]), torch.Size([80])\n",
            "\n",
            "Creating dataloaders...\n",
            "Dataloaders created!\n",
            "Dataloaders sizes:\n",
            "360, 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "2aSyQDx9Bvli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "savePath = '/content/drive/MyDrive/TCC Resultados/AQ_Sample_KFold_1-2'\n",
        "if not os.path.isdir(savePath):\n",
        "  os.mkdir(savePath)\n",
        "kfsetup_AQ_smpl.kfold_train(epochs, savePath, debug = debug, scheduler = scheduler,\n",
        "                    saveBest = saveBest, highestBest = highestBest, print_CUDA = print_CUDA,\n",
        "                    saveEpochMetrics = saveEpochMetrics, fold_metrics = fold_metrics, train = train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c275ed43-6fdc-4194-a7af-17f038ddd56a",
        "id": "P3qSyV53Bvli"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************************************************************************************************************************************************************************************\n",
            "Training fold 1...\n",
            "********************************************************************************************************************************************************************************************************\n",
            "\n",
            "Training CV\n",
            "Time for 1st epoch: 0m2s\n",
            "Estimated time for 10 epochs: 0m23s\n",
            "Finished CV training with best metrics:\n",
            "{'epoch': 1, 'epoch_val_metrics': {'RMSE': 1.08, 'PCC': 0.2646, 'SCC': 0.2391}}\n",
            "Time elapsed: 0m24s\n",
            "====================================================================================================\n",
            "Training CS\n",
            "Time for 1st epoch: 0m2s\n",
            "Estimated time for 10 epochs: 0m29s\n",
            "Finished CS training with best metrics:\n",
            "{'epoch': 9, 'epoch_val_metrics': {'RMSE': 1.6669, 'PCC': 0.1836, 'SCC': 0.1908}}\n",
            "Time elapsed: 0m30s\n",
            "====================================================================================================\n",
            "Training RV\n",
            "Time for 1st epoch: 0m2s\n",
            "Estimated time for 10 epochs: 0m22s\n",
            "Finished RV training with best metrics:\n",
            "{'epoch': 9, 'epoch_val_metrics': {'RMSE': 0.929, 'PCC': 0.5182, 'SCC': 0.5656}}\n",
            "Time elapsed: 0m22s\n",
            "====================================================================================================\n",
            "Training RS\n",
            "Time for 1st epoch: 0m2s\n",
            "Estimated time for 10 epochs: 0m29s\n",
            "Finished RS training with best metrics:\n",
            "{'epoch': 6, 'epoch_val_metrics': {'RMSE': 1.0399, 'PCC': 0.2604, 'SCC': 0.2392}}\n",
            "Time elapsed: 0m29s\n",
            "====================================================================================================\n",
            "Total time elapsed on fold 1: 1m47s\n",
            "\n",
            "********************************************************************************************************************************************************************************************************\n",
            "Training fold 2...\n",
            "********************************************************************************************************************************************************************************************************\n",
            "\n",
            "Training CV\n",
            "Time for 1st epoch: 0m2s\n",
            "Estimated time for 10 epochs: 0m22s\n",
            "Finished CV training with best metrics:\n",
            "{'epoch': 5, 'epoch_val_metrics': {'RMSE': 1.0877, 'PCC': 0.1365, 'SCC': 0.1476}}\n",
            "Time elapsed: 0m23s\n",
            "====================================================================================================\n",
            "Training CS\n",
            "Time for 1st epoch: 0m2s\n",
            "Estimated time for 10 epochs: 0m29s\n",
            "Finished CS training with best metrics:\n",
            "{'epoch': 4, 'epoch_val_metrics': {'RMSE': 1.6752, 'PCC': 0.3124, 'SCC': 0.1908}}\n",
            "Time elapsed: 0m31s\n",
            "====================================================================================================\n",
            "Training RV\n",
            "Time for 1st epoch: 0m2s\n",
            "Estimated time for 10 epochs: 0m23s\n",
            "Finished RV training with best metrics:\n",
            "{'epoch': 6, 'epoch_val_metrics': {'RMSE': 1.0316, 'PCC': 0.3143, 'SCC': 0.187}}\n",
            "Time elapsed: 0m23s\n",
            "====================================================================================================\n",
            "Training RS\n",
            "Time for 1st epoch: 0m2s\n",
            "Estimated time for 10 epochs: 0m29s\n",
            "Finished RS training with best metrics:\n",
            "{'epoch': 10, 'epoch_val_metrics': {'RMSE': 1.0342, 'PCC': 0.176, 'SCC': 0.1912}}\n",
            "Time elapsed: 0m29s\n",
            "====================================================================================================\n",
            "Total time elapsed on fold 2: 1m47s\n",
            "\n",
            "****************************************************************************************************\n",
            "Finished training KFold Cross Validation!\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train using only video features"
      ],
      "metadata": {
        "id": "2i89YdDyB0QO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Original data"
      ],
      "metadata": {
        "id": "CIvNb0kjB0QO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Params and data"
      ],
      "metadata": {
        "id": "wmr0He6fB0QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del kfsetup_AQ_smpl\n",
        "\n",
        "modelVidParams = {\n",
        "'emb_dim': 8,\n",
        "'seq_len': 1187,\n",
        "'num_features': 90,\n",
        "'nhead': 4,\n",
        "'d_hid': 32,\n",
        "'nlayers': 4,\n",
        "'emb_activ': nn.GELU,\n",
        "'linear_activ': nn.GELU,\n",
        "'dropout': 0.1,\n",
        "'batch_first': True\n",
        "}\n",
        "\n",
        "modelSmplParams = {\n",
        "'emb_dim': 4,\n",
        "'seq_len': 1187,\n",
        "'num_features': 90,\n",
        "'nhead': 4,\n",
        "'d_hid': 32,\n",
        "'nlayers': 2,\n",
        "'emb_activ': nn.GELU,\n",
        "'linear_activ': nn.GELU,\n",
        "'dropout': 0.1,\n",
        "'batch_first': True\n",
        "}\n",
        "\n",
        "splitsPath = '/content/drive/MyDrive/TCC Resultados/VQ_KFold_1-2'\n",
        "if not os.path.isdir(splitsPath): os.mkdir(splitsPath)\n",
        "sampling_rate = 1"
      ],
      "metadata": {
        "id": "t5DlkZHmB0QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataParams['debug'] = True\n",
        "kfsetup_VQ = KFoldSetup(n_splits, modelVidParams, modelSmplParams, dataParams, metrics, device, shuffle,\n",
        "                     start_fold, end_fold)\n",
        "kfsetup_VQ.generate_kfold_loaders(X[:, :, :90], y, splitsPath, sampling_rate, kfold_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b0cddc-e9d1-47be-acf9-93eb8fefc64b",
        "id": "2zU9nLciB0QP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data...\n",
            "Train/val data shapes:\n",
            "torch.Size([720, 1187, 90]), torch.Size([80, 1187, 90])\n",
            "torch.Size([720]), torch.Size([80])\n",
            "\n",
            "Creating dataloaders...\n",
            "Dataloaders created!\n",
            "Dataloaders sizes:\n",
            "180, 20\n",
            "Preparing data...\n",
            "Train/val data shapes:\n",
            "torch.Size([720, 1187, 90]), torch.Size([80, 1187, 90])\n",
            "torch.Size([720]), torch.Size([80])\n",
            "\n",
            "Creating dataloaders...\n",
            "Dataloaders created!\n",
            "Dataloaders sizes:\n",
            "360, 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "7o9VJ-aWB0QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "savePath = '/content/drive/MyDrive/TCC Resultados/VQ_KFold_1-2'\n",
        "if not os.path.isdir(savePath):\n",
        "  os.mkdir(savePath)\n",
        "kfsetup_VQ.kfold_train(epochs, savePath, debug = debug, scheduler = scheduler,\n",
        "                    saveBest = saveBest, highestBest = highestBest, print_CUDA = print_CUDA,\n",
        "                    saveEpochMetrics = saveEpochMetrics, fold_metrics = fold_metrics, train = train)"
      ],
      "metadata": {
        "id": "sko0FxfwB0QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downsampled data"
      ],
      "metadata": {
        "id": "PKuxplTUB0QP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Params and data"
      ],
      "metadata": {
        "id": "AcmiAMHYB0QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del kfsetup_VQ\n",
        "\n",
        "modelVidParams = {\n",
        "'emb_dim': 8,\n",
        "'seq_len': 40,\n",
        "'num_features': 90,\n",
        "'nhead': 4,\n",
        "'d_hid': 32,\n",
        "'nlayers': 4,\n",
        "'emb_activ': nn.GELU,\n",
        "'linear_activ': nn.GELU,\n",
        "'dropout': 0.1,\n",
        "'batch_first': True\n",
        "}\n",
        "\n",
        "modelSmplParams = {\n",
        "'emb_dim': 4,\n",
        "'seq_len': 40,\n",
        "'num_features': 90,\n",
        "'nhead': 4,\n",
        "'d_hid': 32,\n",
        "'nlayers': 2,\n",
        "'emb_activ': nn.GELU,\n",
        "'linear_activ': nn.GELU,\n",
        "'dropout': 0.1,\n",
        "'batch_first': True\n",
        "}\n",
        "\n",
        "splitsPath = '/content/drive/MyDrive/TCC Resultados/VQ_Sample_KFold_1-2'\n",
        "if not os.path.isdir(splitsPath): os.mkdir(splitsPath)\n",
        "sampling_rate = 30"
      ],
      "metadata": {
        "id": "oGqqTeLwB0QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataParams['debug'] = True\n",
        "kfsetup_VQ_smpl = KFoldSetup(n_splits, modelVidParams, modelSmplParams, dataParams, metrics, device, shuffle,\n",
        "                     start_fold, end_fold)\n",
        "kfsetup_VQ_smpl.generate_kfold_loaders(X[:, :, :90], y, splitsPath, sampling_rate, kfold_splits)"
      ],
      "metadata": {
        "id": "9TDAMKyJB0QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "DW14CfnWB0QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "savePath = '/content/drive/MyDrive/TCC Resultados/VQ_Sample_KFold_1-2'\n",
        "if not os.path.isdir(savePath):\n",
        "  os.mkdir(savePath)\n",
        "kfsetup_VQ_smpl.kfold_train(epochs, savePath, debug = debug, scheduler = scheduler,\n",
        "                    saveBest = saveBest, highestBest = highestBest, print_CUDA = print_CUDA,\n",
        "                    saveEpochMetrics = saveEpochMetrics, fold_metrics = fold_metrics, train = train)"
      ],
      "metadata": {
        "id": "OH3TvYXqB0QQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "24fasZYuFAkk",
        "O8V7fIT7j2g_",
        "fmYY4G_I5sXE",
        "rpWUZZ1HI8oI",
        "z6M5Ydrg67PU",
        "1eecBuHTECoc",
        "migoIOjAIFuC",
        "TMogSsQj_Gp6",
        "vUejc9OPwngv",
        "c93-e2yhaThd",
        "tqIugKwJGN-c",
        "AAmrWciJ2SL4",
        "FvZD27-H8_lf",
        "0gm6lyRWAJ34",
        "u9Su3GYgAJ39",
        "putgxh04AJ3-",
        "78ReAKS1Bvlc",
        "Al-acU8FBvlh",
        "0CBTHb8YBvli",
        "yD67LXylBvli",
        "q9jl7qBjBvli",
        "2aSyQDx9Bvli",
        "2i89YdDyB0QO",
        "CIvNb0kjB0QO",
        "wmr0He6fB0QP",
        "PKuxplTUB0QP",
        "AcmiAMHYB0QP",
        "DW14CfnWB0QQ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}